{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('3.8.8')",
   "metadata": {
    "interpreter": {
     "hash": "cf9d8c0fb51bb0add3c784a896987d164bd82c904213c50505459851a1becc64"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #https://numpy.org/\n",
    "import pandas as pd #https://pandas.pydata.org/\n",
    "import matplotlib.pyplot as plt #https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG():\n",
    "    input_path=\"./\"#\"../input/tabular-playground-series-apr-2021/\"\n",
    "    debug=False\n",
    "    fold_num=5\n",
    "    seed=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns=['Survived']\n",
    "def feature_columns(df):\n",
    "    for col in df.columns:\n",
    "        if col in target_columns:df=df.drop(columns=col)\n",
    "    return  df.columns\n",
    "def numerical_columns(df):\n",
    "    return df[feature_columns(df)].select_dtypes(include=['int64','float64']).columns\n",
    "def categorical_columns(df):\n",
    "    return df[feature_columns(df)].select_dtypes(exclude=['int64','float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Color:\n",
    "    BLACK     = '\\033[30m'\n",
    "    RED       = '\\033[31m'\n",
    "    GREEN     = '\\033[32m'\n",
    "    YELLOW    = '\\033[33m'\n",
    "    BLUE      = '\\033[34m'\n",
    "    PURPLE    = '\\033[35m'\n",
    "    CYAN      = '\\033[36m'\n",
    "    WHITE     = '\\033[37m'\n",
    "\n",
    "    _BLACK     = '\\033[40m'\n",
    "    _RED       = '\\033[41m'\n",
    "    _GREEN     = '\\033[42m'\n",
    "    _YELLOW    = '\\033[43m'\n",
    "    _BLUE      = '\\033[44m'\n",
    "    _PURPLE    = '\\033[45m'\n",
    "    _CYAN      = '\\033[46m'\n",
    "    _WHITE     = '\\033[47m'\n",
    "\n",
    "    END       = '\\033[0m'\n",
    "    BOLD      = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    INVISIBLE = '\\033[08m'\n",
    "    REVERSE   = '\\033[07m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def what_is(obj):\n",
    "    print(\"type:\",type(obj))\n",
    "    print(\"-\"*40+\"help\"+\"-\"*40)\n",
    "    print(help(obj))\n",
    "    print(\"-\"*40+\"dir\"+\"-\"*40)\n",
    "    print(dir(obj))\n",
    "\n",
    "import pandas_profiling\n",
    "def simple_eda(df):\n",
    "    \"\"\"\n",
    "    simple_eda\n",
    "    \"\"\"\n",
    "    print(\"-\"*40+\"EDA\"+\"-\"*40)\n",
    "    print(\"type:\",type(df))\n",
    "    print(\"-\"*40+\"head\"+\"-\"*40)\n",
    "    display(df.head())\n",
    "    print(\"-\"*40+\"describe\"+\"-\"*40)\n",
    "    display(df.describe())\n",
    "    print(\"-\"*40+\"info\"+\"-\"*40)\n",
    "    print(df.info())\n",
    "\n",
    "    #display(df.profile_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(CFG.input_path+\"train.csv\",index_col='PassengerId')\n",
    "test=pd.read_csv(CFG.input_path+\"test.csv\",index_col='PassengerId')\n",
    "sample_submission=pd.read_csv(CFG.input_path+\"sample_submission.csv\",index_col='PassengerId')\n",
    "\n",
    "if CFG.debug:\n",
    "    train=train[:len(train)//200]\n",
    "    test=test[:len(test)//200]\n",
    "\n",
    "all_data = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------EDA----------------------------------------\ntype: <class 'pandas.core.frame.DataFrame'>\n----------------------------------------head----------------------------------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "             Survived  Pclass              Name   Sex    Age  SibSp  Parch  \\\nPassengerId                                                                  \n0                   1       1  Oconnor, Frankie  male    NaN      2      0   \n1                   0       3       Bryan, Drew  male    NaN      0      0   \n2                   0       3    Owens, Kenneth  male   0.33      1      2   \n3                   0       3     Kramer, James  male  19.00      0      0   \n4                   1       3     Bond, Michael  male  25.00      0      0   \n\n                Ticket   Fare   Cabin Embarked  \nPassengerId                                     \n0               209245  27.14  C12239        S  \n1                27323  13.35     NaN        S  \n2            CA 457703  71.29     NaN        S  \n3             A. 10866  13.04     NaN        S  \n4               427635   7.76     NaN        S  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Oconnor, Frankie</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>0</td>\n      <td>209245</td>\n      <td>27.14</td>\n      <td>C12239</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Bryan, Drew</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>27323</td>\n      <td>13.35</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Owens, Kenneth</td>\n      <td>male</td>\n      <td>0.33</td>\n      <td>1</td>\n      <td>2</td>\n      <td>CA 457703</td>\n      <td>71.29</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Kramer, James</td>\n      <td>male</td>\n      <td>19.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A. 10866</td>\n      <td>13.04</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>3</td>\n      <td>Bond, Michael</td>\n      <td>male</td>\n      <td>25.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>427635</td>\n      <td>7.76</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------describe----------------------------------------\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "            Survived         Pclass           Age          SibSp  \\\ncount  100000.000000  100000.000000  96708.000000  100000.000000   \nmean        0.427740       2.106910     38.355472       0.397690   \nstd         0.494753       0.837727     18.313556       0.862566   \nmin         0.000000       1.000000      0.080000       0.000000   \n25%         0.000000       1.000000     25.000000       0.000000   \n50%         0.000000       2.000000     39.000000       0.000000   \n75%         1.000000       3.000000     53.000000       1.000000   \nmax         1.000000       3.000000     87.000000       8.000000   \n\n               Parch         Fare  \ncount  100000.000000  99866.00000  \nmean        0.454560     43.92933  \nstd         0.950076     69.58882  \nmin         0.000000      0.68000  \n25%         0.000000     10.04000  \n50%         0.000000     24.46000  \n75%         1.000000     33.50000  \nmax         9.000000    744.66000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>100000.000000</td>\n      <td>100000.000000</td>\n      <td>96708.000000</td>\n      <td>100000.000000</td>\n      <td>100000.000000</td>\n      <td>99866.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.427740</td>\n      <td>2.106910</td>\n      <td>38.355472</td>\n      <td>0.397690</td>\n      <td>0.454560</td>\n      <td>43.92933</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.494753</td>\n      <td>0.837727</td>\n      <td>18.313556</td>\n      <td>0.862566</td>\n      <td>0.950076</td>\n      <td>69.58882</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.080000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.68000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>25.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>10.04000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>39.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>24.46000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>53.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>33.50000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>87.000000</td>\n      <td>8.000000</td>\n      <td>9.000000</td>\n      <td>744.66000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------------------------info----------------------------------------\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 100000 entries, 0 to 99999\nData columns (total 11 columns):\n #   Column    Non-Null Count   Dtype  \n---  ------    --------------   -----  \n 0   Survived  100000 non-null  int64  \n 1   Pclass    100000 non-null  int64  \n 2   Name      100000 non-null  object \n 3   Sex       100000 non-null  object \n 4   Age       96708 non-null   float64\n 5   SibSp     100000 non-null  int64  \n 6   Parch     100000 non-null  int64  \n 7   Ticket    95377 non-null   object \n 8   Fare      99866 non-null   float64\n 9   Cabin     32134 non-null   object \n 10  Embarked  99750 non-null   object \ndtypes: float64(2), int64(4), object(5)\nmemory usage: 9.2+ MB\nNone\n"
     ]
    }
   ],
   "source": [
    "simple_eda(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(train.profile_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Survived  Pclass                Name     Sex    Age  SibSp  \\\n",
       "PassengerId                                                               \n",
       "0                 1.0       1    Oconnor, Frankie    male    NaN      2   \n",
       "1                 0.0       3         Bryan, Drew    male    NaN      0   \n",
       "2                 0.0       3      Owens, Kenneth    male   0.33      1   \n",
       "3                 0.0       3       Kramer, James    male  19.00      0   \n",
       "4                 1.0       3       Bond, Michael    male  25.00      0   \n",
       "...               ...     ...                 ...     ...    ...    ...   \n",
       "199995            NaN       3       Cash, Cheryle  female  27.00      0   \n",
       "199996            NaN       1       Brown, Howard    male  59.00      1   \n",
       "199997            NaN       3  Lightfoot, Cameron    male  47.00      0   \n",
       "199998            NaN       1  Jacobsen, Margaret  female  49.00      1   \n",
       "199999            NaN       1    Fishback, Joanna  female  41.00      0   \n",
       "\n",
       "             Parch     Ticket    Fare   Cabin Embarked  \n",
       "PassengerId                                             \n",
       "0                0     209245   27.14  C12239        S  \n",
       "1                0      27323   13.35     NaN        S  \n",
       "2                2  CA 457703   71.29     NaN        S  \n",
       "3                0   A. 10866   13.04     NaN        S  \n",
       "4                0     427635    7.76     NaN        S  \n",
       "...            ...        ...     ...     ...      ...  \n",
       "199995           0       7686   10.12     NaN        Q  \n",
       "199996           0      13004   68.31     NaN        S  \n",
       "199997           0    4383317   10.87     NaN        S  \n",
       "199998           2   PC 26988   29.68  B20828        C  \n",
       "199999           2   PC 41824  195.41  E13345        C  \n",
       "\n",
       "[200000 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Oconnor, Frankie</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>0</td>\n      <td>209245</td>\n      <td>27.14</td>\n      <td>C12239</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Bryan, Drew</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>27323</td>\n      <td>13.35</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Owens, Kenneth</td>\n      <td>male</td>\n      <td>0.33</td>\n      <td>1</td>\n      <td>2</td>\n      <td>CA 457703</td>\n      <td>71.29</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Kramer, James</td>\n      <td>male</td>\n      <td>19.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A. 10866</td>\n      <td>13.04</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>3</td>\n      <td>Bond, Michael</td>\n      <td>male</td>\n      <td>25.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>427635</td>\n      <td>7.76</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Cash, Cheryle</td>\n      <td>female</td>\n      <td>27.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7686</td>\n      <td>10.12</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>NaN</td>\n      <td>1</td>\n      <td>Brown, Howard</td>\n      <td>male</td>\n      <td>59.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>13004</td>\n      <td>68.31</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Lightfoot, Cameron</td>\n      <td>male</td>\n      <td>47.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4383317</td>\n      <td>10.87</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>NaN</td>\n      <td>1</td>\n      <td>Jacobsen, Margaret</td>\n      <td>female</td>\n      <td>49.00</td>\n      <td>1</td>\n      <td>2</td>\n      <td>PC 26988</td>\n      <td>29.68</td>\n      <td>B20828</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>NaN</td>\n      <td>1</td>\n      <td>Fishback, Joanna</td>\n      <td>female</td>\n      <td>41.00</td>\n      <td>0</td>\n      <td>2</td>\n      <td>PC 41824</td>\n      <td>195.41</td>\n      <td>E13345</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=all_data.drop(columns=['Name','Ticket','Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[feature_columns(df)]=df[feature_columns(df)].fillna(df[feature_columns(df)].median())\n",
    "df['Age'].fillna(df['Age'].median(),inplace=True)\n",
    "df['Fare'].fillna(df['Fare'].median(),inplace=True)\n",
    "df=pd.get_dummies(df)\n",
    "#ll_data=pd.get_dummies(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Survived  Pclass    Age  SibSp  Parch    Fare  Sex_female  \\\n",
       "PassengerId                                                              \n",
       "0                 1.0       1  31.00      2      0   27.14           0   \n",
       "1                 0.0       3  31.00      0      0   13.35           0   \n",
       "2                 0.0       3   0.33      1      2   71.29           0   \n",
       "3                 0.0       3  19.00      0      0   13.04           0   \n",
       "4                 1.0       3  25.00      0      0    7.76           0   \n",
       "...               ...     ...    ...    ...    ...     ...         ...   \n",
       "199995            NaN       3  27.00      0      0   10.12           1   \n",
       "199996            NaN       1  59.00      1      0   68.31           0   \n",
       "199997            NaN       3  47.00      0      0   10.87           0   \n",
       "199998            NaN       1  49.00      1      2   29.68           1   \n",
       "199999            NaN       1  41.00      0      2  195.41           1   \n",
       "\n",
       "             Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "PassengerId                                                \n",
       "0                   1           0           0           1  \n",
       "1                   1           0           0           1  \n",
       "2                   1           0           0           1  \n",
       "3                   1           0           0           1  \n",
       "4                   1           0           0           1  \n",
       "...               ...         ...         ...         ...  \n",
       "199995              0           0           1           0  \n",
       "199996              1           0           0           1  \n",
       "199997              1           0           0           1  \n",
       "199998              0           1           0           0  \n",
       "199999              0           1           0           0  \n",
       "\n",
       "[200000 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Sex_female</th>\n      <th>Sex_male</th>\n      <th>Embarked_C</th>\n      <th>Embarked_Q</th>\n      <th>Embarked_S</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1</td>\n      <td>31.00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>27.14</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>3</td>\n      <td>31.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.35</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>3</td>\n      <td>0.33</td>\n      <td>1</td>\n      <td>2</td>\n      <td>71.29</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>3</td>\n      <td>19.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13.04</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>3</td>\n      <td>25.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.76</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>NaN</td>\n      <td>3</td>\n      <td>27.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.12</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>NaN</td>\n      <td>1</td>\n      <td>59.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>68.31</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>NaN</td>\n      <td>3</td>\n      <td>47.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.87</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>NaN</td>\n      <td>1</td>\n      <td>49.00</td>\n      <td>1</td>\n      <td>2</td>\n      <td>29.68</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>NaN</td>\n      <td>1</td>\n      <td>41.00</td>\n      <td>0</td>\n      <td>2</td>\n      <td>195.41</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df[:len(train)]\n",
    "test=df[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(y_pred,y):return (y_pred==y).values.sum()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#from tqdm.notebook import tqdm #peogress bar\n",
    "\n",
    "def cross_validation(X,y,model,test_X=None,NUM_FOLDS=CFG.fold_num,model_name='model'):\n",
    "\n",
    "    kf = KFold(n_splits=NUM_FOLDS, shuffle=False)#,random_state=CFG.seed)\n",
    "    \n",
    "    scores=[]#scoreの配列\n",
    "\n",
    "    test_preds = [0]*len(test_X)#各foldのmodelでのtest_Xに対する予測結果の平均\n",
    "\n",
    "    #stack_training = pd.DataFrame(index=X.index,columns=[model_name])\n",
    "        \n",
    "    for fold_cnt, (tr_idx, val_idx) in enumerate(kf.split(X,y)):\n",
    "            \n",
    "        #tqdm(enumerate(kf.split(x, y))):\n",
    "            \n",
    "        print(f\"FOLD:{fold_cnt}\")\n",
    "        #print(tr_idx,val_idx)\n",
    "\n",
    "        tr_x, tr_y = X.iloc[tr_idx] , y.iloc[tr_idx]\n",
    "        va_x, va_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        tr_y=np.ravel(tr_y)#reshape 1d\n",
    "\n",
    "        #if nn:model=model_func()\n",
    "\n",
    "        model.fit(tr_x, tr_y)\n",
    "\n",
    "        #temp_oof = model.predict(va_x)\n",
    "        pre=model.predict(va_x)\n",
    "\n",
    "        pre=pd.DataFrame(pre,index=va_y.index,columns=['Survived'])\n",
    "        pre=pre>0.5\n",
    "        pre.astype(int)\n",
    "\n",
    "        #stack用\n",
    "        #stack_training['y'].loc[val_idx]=va_y['target']\n",
    "        #stack_training[model_name].iloc[val_idx]=pre[0].ravel()\n",
    "\n",
    "        score=get_score(pre, va_y)\n",
    "        print(Color.GREEN,score,Color.END,sep='')\n",
    "        scores.append(score)\n",
    "\n",
    "        test_preds += model.predict(test_X).ravel()/NUM_FOLDS\n",
    "\n",
    "    \n",
    "    print(Color.RED,\"ave:\",np.average(scores),Color.END,sep='')\n",
    "\n",
    "    # a=cross_val_score(model,X,y,scoring='roc_auc',cv=5)\n",
    "    # print(a)\n",
    "    #return np.average(scores)\n",
    "    #plt.show()\n",
    "    return test_preds,np.average(scores)#,stack_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_params = {\n",
    "    # 'alpha': 100,\n",
    "    # 'max_iter':200,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lasso_params = {\n",
    "    # 'alphas':[0.001],\n",
    "    # 'eps':0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest_params = {\n",
    "    # 'n_estimators': 200,\n",
    "    # #'criterion':'mae',\n",
    "    # 'max_depth':13,\n",
    "    #'min_samples_split':5,\n",
    "}\n",
    "#0.8726983472089088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_params = {\n",
    "    # 'booster':'gbtree',\n",
    "    # 'n_estimators':800,\n",
    "    # 'max_depth':5,\n",
    "    # 'eta':0.01,\n",
    "\n",
    "\n",
    "    # 'num_boost_round':1000,\n",
    "    # 'early_stopping_rounds':50,\n",
    "    #'min_child_weight':1,\n",
    "    # 'alpha':0,\n",
    "    # 'lambda':1,\n",
    "    # 'subsample':0.9,\n",
    "\n",
    "    # 'eval_metric':'auc',\n",
    "    # 'seed': CFG.seed,\n",
    "    # 'tree_method':'gpu_hist',\n",
    "    # 'gpu_id':0\n",
    "\n",
    "    #------------------------\n",
    "\n",
    "    # \"objective\": \"binary:logistic\",\n",
    "    # \"grow_policy\":\"lossguide\",\n",
    "    # \"min_child_weight\":20,\n",
    "    # 'colsample_bytree':0.3,\n",
    "    # 'subsample':0.7,\n",
    "    # 'n_estimators':5000,\n",
    "    # 'learning_rate':0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgbm_params = {\n",
    "    # 'n_estimators':400,\n",
    "    # 'max_depth':2, \n",
    "    # 'learning_rate':0.1,\n",
    "    # 'num_leaves':5,\n",
    "    # 'verbosity':0,\n",
    "    # 'subsample':0.75,\n",
    "    # 'colsample_bytree':0.35,\n",
    "    # 'reg_lambda':0.23,\n",
    "    # 'reg_alpha':0.52,\n",
    "    # 'scale_pos_weight':1,\n",
    "    # 'eval_metric':'auc',\n",
    "    # 'seed': 42,\n",
    "    # 'tree_method':'gpu_hist',\n",
    "    # 'gpu_id':0\n",
    "}\n",
    "#0.881411919700458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "catboost_params = {\n",
    "    # 'iterations':2000,\n",
    "    # 'learning_rate':0.02,\n",
    "    # 'l2_leaf_reg':3.0,\n",
    "    # 'loss_function':'RMSE',\n",
    "    'verbose':0,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LogisticRegression\n",
      "FOLD:0\n",
      "/Users/toutatsu/.anyenv/envs/pyenv/versions/3.8.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m0.76485\u001b[0m\n",
      "FOLD:1\n",
      "/Users/toutatsu/.anyenv/envs/pyenv/versions/3.8.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m0.768\u001b[0m\n",
      "FOLD:2\n",
      "/Users/toutatsu/.anyenv/envs/pyenv/versions/3.8.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m0.768\u001b[0m\n",
      "FOLD:3\n",
      "/Users/toutatsu/.anyenv/envs/pyenv/versions/3.8.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m0.76495\u001b[0m\n",
      "FOLD:4\n",
      "\u001b[32m0.7669\u001b[0m\n",
      "\u001b[31mave:0.7665400000000001\u001b[0m\n",
      "Ridge\n",
      "FOLD:0\n",
      "\u001b[32m0.76455\u001b[0m\n",
      "FOLD:1\n",
      "\u001b[32m0.7694\u001b[0m\n",
      "FOLD:2\n",
      "\u001b[32m0.76695\u001b[0m\n",
      "FOLD:3\n",
      "\u001b[32m0.7642\u001b[0m\n",
      "FOLD:4\n",
      "\u001b[32m0.7666\u001b[0m\n",
      "\u001b[31mave:0.76634\u001b[0m\n",
      "LassoCV\n",
      "FOLD:0\n",
      "\u001b[32m0.75985\u001b[0m\n",
      "FOLD:1\n",
      "\u001b[32m0.7664\u001b[0m\n",
      "FOLD:2\n",
      "\u001b[32m0.76225\u001b[0m\n",
      "FOLD:3\n",
      "\u001b[32m0.75985\u001b[0m\n",
      "FOLD:4\n",
      "\u001b[32m0.76165\u001b[0m\n",
      "\u001b[31mave:0.762\u001b[0m\n",
      "RandomForestRegressor\n",
      "FOLD:0\n",
      "\u001b[32m0.73265\u001b[0m\n",
      "FOLD:1\n",
      "\u001b[32m0.73185\u001b[0m\n",
      "FOLD:2\n",
      "\u001b[32m0.72875\u001b[0m\n",
      "FOLD:3\n",
      "\u001b[32m0.72415\u001b[0m\n",
      "FOLD:4\n",
      "\u001b[32m0.7282\u001b[0m\n",
      "\u001b[31mave:0.72912\u001b[0m\n",
      "XGBRegressor\n",
      "FOLD:0\n",
      "\u001b[32m0.76715\u001b[0m\n",
      "FOLD:1\n",
      "\u001b[32m0.77075\u001b[0m\n",
      "FOLD:2\n",
      "\u001b[32m0.77105\u001b[0m\n",
      "FOLD:3\n",
      "\u001b[32m0.7674\u001b[0m\n",
      "FOLD:4\n",
      "\u001b[32m0.7688\u001b[0m\n",
      "\u001b[31mave:0.7690300000000001\u001b[0m\n",
      "LGBMRegressor\n",
      "FOLD:0\n",
      "\u001b[32m0.77065\u001b[0m\n",
      "FOLD:1\n",
      "\u001b[32m0.7721\u001b[0m\n",
      "FOLD:2\n",
      "\u001b[32m0.7723\u001b[0m\n",
      "FOLD:3\n",
      "\u001b[32m0.77085\u001b[0m\n",
      "FOLD:4\n",
      "\u001b[32m0.7713\u001b[0m\n",
      "\u001b[31mave:0.7714399999999999\u001b[0m\n",
      "CatBoostRegressor\n",
      "FOLD:0\n",
      "\u001b[32m0.7706\u001b[0m\n",
      "FOLD:1\n",
      "\u001b[32m0.77225\u001b[0m\n",
      "FOLD:2\n",
      "\u001b[32m0.7723\u001b[0m\n",
      "FOLD:3\n",
      "\u001b[32m0.7698\u001b[0m\n",
      "FOLD:4\n",
      "\u001b[32m0.7717\u001b[0m\n",
      "\u001b[31mave:0.7713300000000001\u001b[0m\n",
      "LinearSVC\n",
      "FOLD:0\n",
      "/Users/toutatsu/.anyenv/envs/pyenv/versions/3.8.8/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "\u001b[32m0.6282\u001b[0m\n",
      "FOLD:1\n",
      "/Users/toutatsu/.anyenv/envs/pyenv/versions/3.8.8/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "\u001b[32m0.6565\u001b[0m\n",
      "FOLD:2\n",
      "/Users/toutatsu/.anyenv/envs/pyenv/versions/3.8.8/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "\u001b[32m0.72555\u001b[0m\n",
      "FOLD:3\n",
      "/Users/toutatsu/.anyenv/envs/pyenv/versions/3.8.8/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "\u001b[32m0.57735\u001b[0m\n",
      "FOLD:4\n",
      "/Users/toutatsu/.anyenv/envs/pyenv/versions/3.8.8/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "\u001b[32m0.63375\u001b[0m\n",
      "\u001b[31mave:0.64427\u001b[0m\n",
      "MLPRegressor\n",
      "FOLD:0\n",
      "\u001b[32m0.7236\u001b[0m\n",
      "FOLD:1\n",
      "\u001b[32m0.76735\u001b[0m\n",
      "FOLD:2\n",
      "\u001b[32m0.7665\u001b[0m\n",
      "FOLD:3\n",
      "\u001b[32m0.7644\u001b[0m\n",
      "FOLD:4\n",
      "\u001b[32m0.7654\u001b[0m\n",
      "\u001b[31mave:0.75745\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "models=[\n",
    "    LogisticRegression(),\n",
    "    Ridge(**ridge_params),\n",
    "    LassoCV(**lasso_params),\n",
    "    RandomForestRegressor(**random_forest_params),\n",
    "    XGBRegressor(**xgb_params),\n",
    "    LGBMRegressor(**lgbm_params),\n",
    "    CatBoostRegressor(**catboost_params),\n",
    "    #SVC(),\n",
    "    LinearSVC(),\n",
    "    MLPRegressor(),\n",
    "]\n",
    "model_names=[\n",
    "    'LogisticRegression',\n",
    "    'Ridge',\n",
    "    'LassoCV',\n",
    "    'RandomForestRegressor',\n",
    "    'XGBRegressor',\n",
    "    'LGBMRegressor',\n",
    "    'CatBoostRegressor',\n",
    "    #'SVC',\n",
    "    'LinearSVC',\n",
    "    'MLPRegressor',\n",
    "]\n",
    "predictions=pd.DataFrame(index=test.index)\n",
    "ave_scores=pd.DataFrame(index=model_names,columns=['score'])\n",
    "\n",
    "for idx,model in enumerate(models):\n",
    "    print(model_names[idx])\n",
    "\n",
    "    predictions[model_names[idx]],ave_scores.loc[model_names[idx]]=cross_validation(train[feature_columns(train)],train[target_columns],model,test_X=test[feature_columns(test)],model_name=model_names[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             LogisticRegression     Ridge   LassoCV  RandomForestRegressor  \\\n",
       "PassengerId                                                                  \n",
       "100000                      0.0  0.131324  0.143871                 0.0980   \n",
       "100001                      1.0  0.542767  0.538717                 0.3660   \n",
       "100002                      1.0  0.925243  0.871608                 0.9520   \n",
       "100003                      0.0  0.202464  0.205463                 0.3051   \n",
       "100004                      1.0  0.902849  0.862386                 0.3820   \n",
       "...                         ...       ...       ...                    ...   \n",
       "199995                      1.0  0.584573  0.575232                 0.2880   \n",
       "199996                      0.0  0.287944  0.303461                 0.2060   \n",
       "199997                      0.0  0.123021  0.138237                 0.0520   \n",
       "199998                      1.0  0.895085  0.869935                 0.7720   \n",
       "199999                      1.0  0.942570  0.920369                 0.6600   \n",
       "\n",
       "             XGBRegressor  LGBMRegressor  CatBoostRegressor  LinearSVC  \\\n",
       "PassengerId                                                              \n",
       "100000           0.073420       0.085921           0.091738        0.2   \n",
       "100001           0.568140       0.508120           0.530147        0.6   \n",
       "100002           1.024265       0.944579           0.962630        0.8   \n",
       "100003           0.324666       0.199823           0.209890        0.0   \n",
       "100004           0.646306       0.693036           0.681852        1.0   \n",
       "...                   ...            ...                ...        ...   \n",
       "199995           0.583340       0.577654           0.590258        0.6   \n",
       "199996           0.177140       0.191864           0.154001        0.2   \n",
       "199997           0.077462       0.071876           0.073248        0.0   \n",
       "199998           0.672139       0.666026           0.635863        0.6   \n",
       "199999           0.753167       0.794495           0.788967        0.4   \n",
       "\n",
       "             MLPRegressor       ave  \n",
       "PassengerId                          \n",
       "100000           0.152608  0.108542  \n",
       "100001           0.494387  0.572031  \n",
       "100002           0.913861  0.932687  \n",
       "100003           0.156066  0.178163  \n",
       "100004           0.830311  0.777638  \n",
       "...                   ...       ...  \n",
       "199995           0.573105  0.596907  \n",
       "199996           0.167463  0.187542  \n",
       "199997           0.009763  0.060623  \n",
       "199998           0.805151  0.768467  \n",
       "199999           0.812519  0.785787  \n",
       "\n",
       "[100000 rows x 10 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LogisticRegression</th>\n      <th>Ridge</th>\n      <th>LassoCV</th>\n      <th>RandomForestRegressor</th>\n      <th>XGBRegressor</th>\n      <th>LGBMRegressor</th>\n      <th>CatBoostRegressor</th>\n      <th>LinearSVC</th>\n      <th>MLPRegressor</th>\n      <th>ave</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>100000</th>\n      <td>0.0</td>\n      <td>0.131324</td>\n      <td>0.143871</td>\n      <td>0.0980</td>\n      <td>0.073420</td>\n      <td>0.085921</td>\n      <td>0.091738</td>\n      <td>0.2</td>\n      <td>0.152608</td>\n      <td>0.108542</td>\n    </tr>\n    <tr>\n      <th>100001</th>\n      <td>1.0</td>\n      <td>0.542767</td>\n      <td>0.538717</td>\n      <td>0.3660</td>\n      <td>0.568140</td>\n      <td>0.508120</td>\n      <td>0.530147</td>\n      <td>0.6</td>\n      <td>0.494387</td>\n      <td>0.572031</td>\n    </tr>\n    <tr>\n      <th>100002</th>\n      <td>1.0</td>\n      <td>0.925243</td>\n      <td>0.871608</td>\n      <td>0.9520</td>\n      <td>1.024265</td>\n      <td>0.944579</td>\n      <td>0.962630</td>\n      <td>0.8</td>\n      <td>0.913861</td>\n      <td>0.932687</td>\n    </tr>\n    <tr>\n      <th>100003</th>\n      <td>0.0</td>\n      <td>0.202464</td>\n      <td>0.205463</td>\n      <td>0.3051</td>\n      <td>0.324666</td>\n      <td>0.199823</td>\n      <td>0.209890</td>\n      <td>0.0</td>\n      <td>0.156066</td>\n      <td>0.178163</td>\n    </tr>\n    <tr>\n      <th>100004</th>\n      <td>1.0</td>\n      <td>0.902849</td>\n      <td>0.862386</td>\n      <td>0.3820</td>\n      <td>0.646306</td>\n      <td>0.693036</td>\n      <td>0.681852</td>\n      <td>1.0</td>\n      <td>0.830311</td>\n      <td>0.777638</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>1.0</td>\n      <td>0.584573</td>\n      <td>0.575232</td>\n      <td>0.2880</td>\n      <td>0.583340</td>\n      <td>0.577654</td>\n      <td>0.590258</td>\n      <td>0.6</td>\n      <td>0.573105</td>\n      <td>0.596907</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>0.0</td>\n      <td>0.287944</td>\n      <td>0.303461</td>\n      <td>0.2060</td>\n      <td>0.177140</td>\n      <td>0.191864</td>\n      <td>0.154001</td>\n      <td>0.2</td>\n      <td>0.167463</td>\n      <td>0.187542</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>0.0</td>\n      <td>0.123021</td>\n      <td>0.138237</td>\n      <td>0.0520</td>\n      <td>0.077462</td>\n      <td>0.071876</td>\n      <td>0.073248</td>\n      <td>0.0</td>\n      <td>0.009763</td>\n      <td>0.060623</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>1.0</td>\n      <td>0.895085</td>\n      <td>0.869935</td>\n      <td>0.7720</td>\n      <td>0.672139</td>\n      <td>0.666026</td>\n      <td>0.635863</td>\n      <td>0.6</td>\n      <td>0.805151</td>\n      <td>0.768467</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>1.0</td>\n      <td>0.942570</td>\n      <td>0.920369</td>\n      <td>0.6600</td>\n      <td>0.753167</td>\n      <td>0.794495</td>\n      <td>0.788967</td>\n      <td>0.4</td>\n      <td>0.812519</td>\n      <td>0.785787</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "predictions['ave']=predictions.mean(axis=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.ave=(predictions.ave>0.5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                         score\n",
       "LogisticRegression     0.76654\n",
       "Ridge                  0.76634\n",
       "LassoCV                  0.762\n",
       "RandomForestRegressor  0.72912\n",
       "XGBRegressor           0.76903\n",
       "LGBMRegressor          0.77144\n",
       "CatBoostRegressor      0.77133\n",
       "LinearSVC              0.64427\n",
       "MLPRegressor           0.75745"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LogisticRegression</th>\n      <td>0.76654</td>\n    </tr>\n    <tr>\n      <th>Ridge</th>\n      <td>0.76634</td>\n    </tr>\n    <tr>\n      <th>LassoCV</th>\n      <td>0.762</td>\n    </tr>\n    <tr>\n      <th>RandomForestRegressor</th>\n      <td>0.72912</td>\n    </tr>\n    <tr>\n      <th>XGBRegressor</th>\n      <td>0.76903</td>\n    </tr>\n    <tr>\n      <th>LGBMRegressor</th>\n      <td>0.77144</td>\n    </tr>\n    <tr>\n      <th>CatBoostRegressor</th>\n      <td>0.77133</td>\n    </tr>\n    <tr>\n      <th>LinearSVC</th>\n      <td>0.64427</td>\n    </tr>\n    <tr>\n      <th>MLPRegressor</th>\n      <td>0.75745</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "ave_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Survived\n",
       "PassengerId          \n",
       "100000              0\n",
       "100001              1\n",
       "100002              1\n",
       "100003              0\n",
       "100004              1\n",
       "...               ...\n",
       "199995              1\n",
       "199996              0\n",
       "199997              0\n",
       "199998              1\n",
       "199999              1\n",
       "\n",
       "[100000 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>100000</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>100001</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>100002</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>100003</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>100004</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "submission=pd.DataFrame(columns=['PassengerId','Survived'],dtype='int64')\n",
    "submission.PassengerId=test.index\n",
    "submission=submission.set_index('PassengerId')\n",
    "#submission.Survived=[ int(x=='female') for x in test.Sex ]\n",
    "submission['Survived']=predictions.ave\n",
    "\n",
    "submission.to_csv(\"submission.csv\")\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}