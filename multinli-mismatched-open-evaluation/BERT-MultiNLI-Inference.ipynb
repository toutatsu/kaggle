{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c7db06",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-06T04:20:49.541610Z",
     "iopub.status.busy": "2022-03-06T04:20:49.540726Z",
     "iopub.status.idle": "2022-03-06T04:20:54.907998Z",
     "shell.execute_reply": "2022-03-06T04:20:54.907403Z",
     "shell.execute_reply.started": "2021-10-11T11:53:58.707976Z"
    },
    "papermill": {
     "duration": 5.465472,
     "end_time": "2022-03-06T04:20:54.908152",
     "exception": false,
     "start_time": "2022-03-06T04:20:49.442680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#defaul libraries\n",
    "#https://docs.python.org/ja/\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import math\n",
    "import random\n",
    "import pprint\n",
    "import time\n",
    "import datetime\n",
    "import typing\n",
    "import json\n",
    "import glob\n",
    "import requests\n",
    "import warnings\n",
    "import gc\n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "import numpy as np #https://numpy.org/\n",
    "import pandas as pd #https://pandas.pydata.org/\n",
    "import sklearn #https://scikit-learn.org/stable/\n",
    "\n",
    "import matplotlib.pyplot as plt #https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from tqdm import tqdm #https://tqdm.github.io/\n",
    "\n",
    "import torch #https://pytorch.org/\n",
    "import transformers #https://huggingface.co/transformers/\n",
    "\n",
    "#import torchvision\n",
    "#import torchtext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafb1c3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:20:55.009959Z",
     "iopub.status.busy": "2022-03-06T04:20:55.008835Z",
     "iopub.status.idle": "2022-03-06T04:20:55.017396Z",
     "shell.execute_reply": "2022-03-06T04:20:55.017849Z",
     "shell.execute_reply.started": "2021-10-11T11:54:04.0124Z"
    },
    "papermill": {
     "duration": 0.083795,
     "end_time": "2022-03-06T04:20:55.018017",
     "exception": false,
     "start_time": "2022-03-06T04:20:54.934222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "0\n",
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "class CFG():\n",
    "    \n",
    "    data_path=\"../input/multinli-mismatched-open-evaluation/\"#\"./multinli_1.0/\"\n",
    "    debug=False\n",
    "    seed=0\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    batch_size=8\n",
    "    epochs=2\n",
    "    learning_rate=2e-5\n",
    "    kFold=1\n",
    "\n",
    "\n",
    "    #高速化関連\n",
    "    #https://qiita.com/sugulu_Ogawa_ISID/items/62f5f7adee083d96a587\n",
    "\n",
    "    #GPU 遅くなるらしい↓\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    #イテレーションごとのnnの順伝搬および誤差関数の 計算手法がある程度一定であれば、torch.backends.cudnn.benchmark = Trueで GPU での計算が高速化\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    #tf.random.set_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(CFG.seed)\n",
    "\n",
    "print(CFG.device)\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.current_device())\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7180125e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:20:55.073004Z",
     "iopub.status.busy": "2022-03-06T04:20:55.072085Z",
     "iopub.status.idle": "2022-03-06T04:20:55.074534Z",
     "shell.execute_reply": "2022-03-06T04:20:55.074148Z",
     "shell.execute_reply.started": "2021-10-11T11:54:04.070985Z"
    },
    "papermill": {
     "duration": 0.031542,
     "end_time": "2022-03-06T04:20:55.074635",
     "exception": false,
     "start_time": "2022-03-06T04:20:55.043093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def color(string,fg='DEFAULT',bg='DEFAULT',fg_rgb=None,bg_rgb=None,style='END'):\n",
    "    colors=['BLACK','RED','GREEN','YELLOW','BLUE','PURPLE','CYAN','WHITE','8','DEFAULT']\n",
    "    styles=['END','BOLD','2','3','UNDERLINE','5','6','REVERSE','INVISIBLE','9']\n",
    "\n",
    "    fg=f'\\033[3{colors.index(fg)}m'\n",
    "    bg=f'\\033[4{colors.index(bg)}m'\n",
    "    style=f'\\033[0{styles.index(style)}m'\n",
    "\n",
    "    if fg_rgb:fg=f\"\\033[38;2;{fg_rgb[0]};{fg_rgb[1]};{fg_rgb[2]}m\"\n",
    "    if bg_rgb:bg=f\"\\033[48;2;{bg_rgb[0]};{bg_rgb[1]};{bg_rgb[2]}m\"\n",
    "\n",
    "    return style+fg+bg+str(string)+'\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31e46c31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:20:55.126148Z",
     "iopub.status.busy": "2022-03-06T04:20:55.125493Z",
     "iopub.status.idle": "2022-03-06T04:20:55.128542Z",
     "shell.execute_reply": "2022-03-06T04:20:55.129120Z",
     "shell.execute_reply.started": "2021-10-11T11:54:04.080113Z"
    },
    "papermill": {
     "duration": 0.031873,
     "end_time": "2022-03-06T04:20:55.129271",
     "exception": false,
     "start_time": "2022-03-06T04:20:55.097398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01m\u001b[32m\u001b[49mcolor test\u001b[0m\n",
      "\u001b[04m\u001b[31m\u001b[44mcolor test\u001b[0m\n",
      "\u001b[08m\u001b[36m\u001b[47mcolor test\u001b[0m\n",
      "\u001b[07m\u001b[36m\u001b[49mcolor test\u001b[0m\n",
      "\u001b[00m\u001b[38;2;150;150;255m\u001b[49maaa\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(color(\"color test\",\"GREEN\",style='BOLD'))\n",
    "print(color(\"color test\",\"RED\",\"BLUE\",style='UNDERLINE'))\n",
    "print(color(\"color test\",\"CYAN\",\"WHITE\",style='INVISIBLE'))\n",
    "print(color(\"color test\",\"CYAN\",style='REVERSE'))\n",
    "print(color(\"aaa\",fg_rgb=(150,150,255)))\n",
    "# print(color(\"bbb\",fg_rgb=(0,250,50),bg_rgb=(0,0,255)))\n",
    "# print(color(\"ccc\"))\n",
    "# print(color('style',bg=\"RED\",fg='BLUE'))\n",
    "# print('\\033[07m'+\"Aa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "157952cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:20:55.185975Z",
     "iopub.status.busy": "2022-03-06T04:20:55.185160Z",
     "iopub.status.idle": "2022-03-06T04:20:55.187488Z",
     "shell.execute_reply": "2022-03-06T04:20:55.187001Z",
     "shell.execute_reply.started": "2021-10-11T11:54:04.095515Z"
    },
    "papermill": {
     "duration": 0.034032,
     "end_time": "2022-03-06T04:20:55.187583",
     "exception": false,
     "start_time": "2022-03-06T04:20:55.153551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "class SlackNotifier():\n",
    "    \n",
    "    def __init__(self,token,channel):\n",
    "        self.token=token\n",
    "        self.channel=channel\n",
    "    \n",
    "    def textblock(self,text):\n",
    "        blocks=json.dumps(\n",
    "            [#ヘッダー\n",
    "                #現在時刻\n",
    "                {\n",
    "                    \"type\": \"context\",\n",
    "                    \"elements\": [\n",
    "                        {\n",
    "                            \"type\": \"plain_text\",\n",
    "                            \"text\": (datetime.datetime.utcnow() + datetime.timedelta(hours=9)).strftime('%Y年%m月%d日 %H:%M:%S'),\n",
    "                            \"emoji\": True\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                {\"type\": \"divider\"},\n",
    "                {\n",
    "                    \"type\": \"section\",\n",
    "                    \"text\": {\n",
    "                        \"type\": \"mrkdwn\",\n",
    "                        \"text\": text\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "        )\n",
    "        return blocks\n",
    "    \n",
    "    def post(self,message):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def update(self,timestamp,blocks):\n",
    "        \n",
    "        response=requests.post(\n",
    "            \"https://slack.com/api/chat.update\",\n",
    "            data={\n",
    "                \"token\":self.token,\n",
    "                \"channel\":self.channel,\n",
    "                \"ts\":timestamp,\n",
    "                #\"blocks\":\n",
    "                'blocks':blocks,\n",
    "            },\n",
    "        )\n",
    "        return response\n",
    "    \n",
    "token=\"\"\n",
    "channel=\"\"\n",
    "timestamp=\"\"\n",
    "\n",
    "slack=SlackNotifier(token,channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf179362",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:20:55.238056Z",
     "iopub.status.busy": "2022-03-06T04:20:55.237339Z",
     "iopub.status.idle": "2022-03-06T04:20:55.570767Z",
     "shell.execute_reply": "2022-03-06T04:20:55.570268Z",
     "shell.execute_reply.started": "2021-10-11T11:54:04.107461Z"
    },
    "papermill": {
     "duration": 0.360251,
     "end_time": "2022-03-06T04:20:55.570903",
     "exception": false,
     "start_time": "2022-03-06T04:20:55.210652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "multi_nli_test_mismatched=pd.read_json(CFG.data_path+'multinli_0.9_test_mismatched_unlabeled.jsonl',orient='records',lines=True)\n",
    "\n",
    "\n",
    "if CFG.debug:\n",
    "    multi_nli_test_mismatched=multi_nli_test_mismatched.sample(frac=0.01).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e2716c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:20:55.624803Z",
     "iopub.status.busy": "2022-03-06T04:20:55.624268Z",
     "iopub.status.idle": "2022-03-06T04:20:55.648659Z",
     "shell.execute_reply": "2022-03-06T04:20:55.649080Z",
     "shell.execute_reply.started": "2021-10-11T11:54:04.632081Z"
    },
    "papermill": {
     "duration": 0.054232,
     "end_time": "2022-03-06T04:20:55.649208",
     "exception": false,
     "start_time": "2022-03-06T04:20:55.594976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator_labels</th>\n",
       "      <th>genre</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>pairID</th>\n",
       "      <th>promptID</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence1_binary_parse</th>\n",
       "      <th>sentence1_parse</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence2_binary_parse</th>\n",
       "      <th>sentence2_parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>oup</td>\n",
       "      <td>hidden</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Even here, the channel perspective tells a som...</td>\n",
       "      <td>( ( Even here ) ( , ( ( the ( channel perspect...</td>\n",
       "      <td>(ROOT (S (ADVP (RB Even) (RB here)) (, ,) (NP ...</td>\n",
       "      <td>The story told by the channel is slightly diff...</td>\n",
       "      <td>( ( ( The story ) ( told ( by ( the channel ) ...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT The) (NN story)) (VP (VBN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>verbatim</td>\n",
       "      <td>hidden</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>My theory is that the  r got put in there simp...</td>\n",
       "      <td>( ( My theory ) ( ( is ( that ( ( the r ) ( ( ...</td>\n",
       "      <td>(ROOT (S (NP (PRP$ My) (NN theory)) (VP (VBZ i...</td>\n",
       "      <td>I think the r is there just because people are...</td>\n",
       "      <td>( I ( ( think ( ( the r ) ( ( is there ) ( jus...</td>\n",
       "      <td>(ROOT (S (NP (PRP I)) (VP (VBP think) (SBAR (S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>verbatim</td>\n",
       "      <td>hidden</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>To go on using in its former sense a word whos...</td>\n",
       "      <td>( ( To ( go ( on ( ( using ( in ( its ( former...</td>\n",
       "      <td>(ROOT (S (S (VP (TO To) (VP (VB go) (PP (IN on...</td>\n",
       "      <td>To go on using it in its former sense could be...</td>\n",
       "      <td>( ( To ( go ( on ( ( using it ) ( in ( its ( f...</td>\n",
       "      <td>(ROOT (NP (S (S (VP (TO To) (VP (VB go) (PP (I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>nineeleven</td>\n",
       "      <td>hidden</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>He alerted his supervisor, who assigned anothe...</td>\n",
       "      <td>( He ( ( alerted ( ( ( his supervisor ) , ) ( ...</td>\n",
       "      <td>(ROOT (S (NP (PRP He)) (VP (VBD alerted) (NP (...</td>\n",
       "      <td>The supervisor had another controller work wit...</td>\n",
       "      <td>( ( The supervisor ) ( ( had ( ( another ( con...</td>\n",
       "      <td>(ROOT (S (NP (DT The) (NN supervisor)) (VP (VB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>letters</td>\n",
       "      <td>hidden</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>I have also enclosed a brief report on those a...</td>\n",
       "      <td>( I ( ( ( have also ) ( ( enclosed ( a ( brief...</td>\n",
       "      <td>(ROOT (S (NP (PRP I)) (VP (VBP have) (ADVP (RB...</td>\n",
       "      <td>Your annual contribution will have little impact.</td>\n",
       "      <td>( ( Your ( annual contribution ) ) ( ( will ( ...</td>\n",
       "      <td>(ROOT (S (NP (PRP$ Your) (JJ annual) (NN contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9842</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>facetoface</td>\n",
       "      <td>hidden</td>\n",
       "      <td>9842</td>\n",
       "      <td>9842</td>\n",
       "      <td>Grandmom smoked Saratoga 120 cigarettes which ...</td>\n",
       "      <td>( Grandmom ( ( smoked ( ( Saratoga ( 120 cigar...</td>\n",
       "      <td>(ROOT (S (NP (NNP Grandmom)) (VP (VBD smoked) ...</td>\n",
       "      <td>Those really long Saratoga 120 cigarettes are ...</td>\n",
       "      <td>( ( Those ( ( really long ) ( Saratoga ( 120 c...</td>\n",
       "      <td>(ROOT (S (NP (DT Those) (ADJP (RB really) (JJ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9843</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>oup</td>\n",
       "      <td>hidden</td>\n",
       "      <td>9843</td>\n",
       "      <td>9843</td>\n",
       "      <td>But if order lead times are long, the buyer mu...</td>\n",
       "      <td>( But ( ( ( if order ) ( ( lead times ) ( are ...</td>\n",
       "      <td>(ROOT (S (CC But) (SBAR (IN if) (NN order) (S ...</td>\n",
       "      <td>Orders from China often take longer than expec...</td>\n",
       "      <td>( ( Orders ( from China ) ) ( often ( ( take (...</td>\n",
       "      <td>(ROOT (S (NP (NP (NNS Orders)) (PP (IN from) (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9844</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>nineeleven</td>\n",
       "      <td>hidden</td>\n",
       "      <td>9844</td>\n",
       "      <td>9844</td>\n",
       "      <td>After NEADS learned of the hijacking at 10:07,...</td>\n",
       "      <td>( ( After ( NEADS ( learned ( of ( ( the hijac...</td>\n",
       "      <td>(ROOT (S (PP (IN After) (NP (NP (NNS NEADS)) (...</td>\n",
       "      <td>NEADS learned of the hijacking at 10:07, befor...</td>\n",
       "      <td>( NEADS ( ( ( ( ( learned ( of ( the hijacking...</td>\n",
       "      <td>(ROOT (S (NP (NNS NEADS)) (VP (VBD learned) (P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>facetoface</td>\n",
       "      <td>hidden</td>\n",
       "      <td>9845</td>\n",
       "      <td>9845</td>\n",
       "      <td>I said, And do you think you can help me?</td>\n",
       "      <td>( ( ( ( I said ) , ) And ) ( ( ( do you ) ( th...</td>\n",
       "      <td>(ROOT (S (S (NP (PRP I)) (VP (VBD said))) (, ,...</td>\n",
       "      <td>I asked, so do you think you can help me with ...</td>\n",
       "      <td>( ( ( ( I asked ) , ) so ) ( ( ( do you ) ( th...</td>\n",
       "      <td>(ROOT (S (S (NP (PRP I)) (VP (VBD asked))) (, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9846</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>nineeleven</td>\n",
       "      <td>hidden</td>\n",
       "      <td>9846</td>\n",
       "      <td>9846</td>\n",
       "      <td>Still, he was just one among many diverse terr...</td>\n",
       "      <td>( Still ( , ( he ( ( was ( ( just one ) ( amon...</td>\n",
       "      <td>(ROOT (S (ADVP (RB Still)) (, ,) (NP (PRP he))...</td>\n",
       "      <td>He was just one of many lead terrorists.</td>\n",
       "      <td>( He ( ( was ( ( just one ) ( of ( many ( lead...</td>\n",
       "      <td>(ROOT (S (NP (PRP He)) (VP (VBD was) (NP (NP (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9847 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              annotator_labels       genre gold_label  pairID  \\\n",
       "0     [hidden, hidden, hidden, hidden, hidden]         oup     hidden       0   \n",
       "1     [hidden, hidden, hidden, hidden, hidden]    verbatim     hidden       1   \n",
       "2     [hidden, hidden, hidden, hidden, hidden]    verbatim     hidden       2   \n",
       "3     [hidden, hidden, hidden, hidden, hidden]  nineeleven     hidden       3   \n",
       "4     [hidden, hidden, hidden, hidden, hidden]     letters     hidden       4   \n",
       "...                                        ...         ...        ...     ...   \n",
       "9842  [hidden, hidden, hidden, hidden, hidden]  facetoface     hidden    9842   \n",
       "9843  [hidden, hidden, hidden, hidden, hidden]         oup     hidden    9843   \n",
       "9844  [hidden, hidden, hidden, hidden, hidden]  nineeleven     hidden    9844   \n",
       "9845  [hidden, hidden, hidden, hidden, hidden]  facetoface     hidden    9845   \n",
       "9846  [hidden, hidden, hidden, hidden, hidden]  nineeleven     hidden    9846   \n",
       "\n",
       "      promptID                                          sentence1  \\\n",
       "0            0  Even here, the channel perspective tells a som...   \n",
       "1            1  My theory is that the  r got put in there simp...   \n",
       "2            2  To go on using in its former sense a word whos...   \n",
       "3            3  He alerted his supervisor, who assigned anothe...   \n",
       "4            4  I have also enclosed a brief report on those a...   \n",
       "...        ...                                                ...   \n",
       "9842      9842  Grandmom smoked Saratoga 120 cigarettes which ...   \n",
       "9843      9843  But if order lead times are long, the buyer mu...   \n",
       "9844      9844  After NEADS learned of the hijacking at 10:07,...   \n",
       "9845      9845          I said, And do you think you can help me?   \n",
       "9846      9846  Still, he was just one among many diverse terr...   \n",
       "\n",
       "                                 sentence1_binary_parse  \\\n",
       "0     ( ( Even here ) ( , ( ( the ( channel perspect...   \n",
       "1     ( ( My theory ) ( ( is ( that ( ( the r ) ( ( ...   \n",
       "2     ( ( To ( go ( on ( ( using ( in ( its ( former...   \n",
       "3     ( He ( ( alerted ( ( ( his supervisor ) , ) ( ...   \n",
       "4     ( I ( ( ( have also ) ( ( enclosed ( a ( brief...   \n",
       "...                                                 ...   \n",
       "9842  ( Grandmom ( ( smoked ( ( Saratoga ( 120 cigar...   \n",
       "9843  ( But ( ( ( if order ) ( ( lead times ) ( are ...   \n",
       "9844  ( ( After ( NEADS ( learned ( of ( ( the hijac...   \n",
       "9845  ( ( ( ( I said ) , ) And ) ( ( ( do you ) ( th...   \n",
       "9846  ( Still ( , ( he ( ( was ( ( just one ) ( amon...   \n",
       "\n",
       "                                        sentence1_parse  \\\n",
       "0     (ROOT (S (ADVP (RB Even) (RB here)) (, ,) (NP ...   \n",
       "1     (ROOT (S (NP (PRP$ My) (NN theory)) (VP (VBZ i...   \n",
       "2     (ROOT (S (S (VP (TO To) (VP (VB go) (PP (IN on...   \n",
       "3     (ROOT (S (NP (PRP He)) (VP (VBD alerted) (NP (...   \n",
       "4     (ROOT (S (NP (PRP I)) (VP (VBP have) (ADVP (RB...   \n",
       "...                                                 ...   \n",
       "9842  (ROOT (S (NP (NNP Grandmom)) (VP (VBD smoked) ...   \n",
       "9843  (ROOT (S (CC But) (SBAR (IN if) (NN order) (S ...   \n",
       "9844  (ROOT (S (PP (IN After) (NP (NP (NNS NEADS)) (...   \n",
       "9845  (ROOT (S (S (NP (PRP I)) (VP (VBD said))) (, ,...   \n",
       "9846  (ROOT (S (ADVP (RB Still)) (, ,) (NP (PRP he))...   \n",
       "\n",
       "                                              sentence2  \\\n",
       "0     The story told by the channel is slightly diff...   \n",
       "1     I think the r is there just because people are...   \n",
       "2     To go on using it in its former sense could be...   \n",
       "3     The supervisor had another controller work wit...   \n",
       "4     Your annual contribution will have little impact.   \n",
       "...                                                 ...   \n",
       "9842  Those really long Saratoga 120 cigarettes are ...   \n",
       "9843  Orders from China often take longer than expec...   \n",
       "9844  NEADS learned of the hijacking at 10:07, befor...   \n",
       "9845  I asked, so do you think you can help me with ...   \n",
       "9846          He was just one of many lead terrorists.    \n",
       "\n",
       "                                 sentence2_binary_parse  \\\n",
       "0     ( ( ( The story ) ( told ( by ( the channel ) ...   \n",
       "1     ( I ( ( think ( ( the r ) ( ( is there ) ( jus...   \n",
       "2     ( ( To ( go ( on ( ( using it ) ( in ( its ( f...   \n",
       "3     ( ( The supervisor ) ( ( had ( ( another ( con...   \n",
       "4     ( ( Your ( annual contribution ) ) ( ( will ( ...   \n",
       "...                                                 ...   \n",
       "9842  ( ( Those ( ( really long ) ( Saratoga ( 120 c...   \n",
       "9843  ( ( Orders ( from China ) ) ( often ( ( take (...   \n",
       "9844  ( NEADS ( ( ( ( ( learned ( of ( the hijacking...   \n",
       "9845  ( ( ( ( I asked ) , ) so ) ( ( ( do you ) ( th...   \n",
       "9846  ( He ( ( was ( ( just one ) ( of ( many ( lead...   \n",
       "\n",
       "                                        sentence2_parse  \n",
       "0     (ROOT (S (NP (NP (DT The) (NN story)) (VP (VBN...  \n",
       "1     (ROOT (S (NP (PRP I)) (VP (VBP think) (SBAR (S...  \n",
       "2     (ROOT (NP (S (S (VP (TO To) (VP (VB go) (PP (I...  \n",
       "3     (ROOT (S (NP (DT The) (NN supervisor)) (VP (VB...  \n",
       "4     (ROOT (S (NP (PRP$ Your) (JJ annual) (NN contr...  \n",
       "...                                                 ...  \n",
       "9842  (ROOT (S (NP (DT Those) (ADJP (RB really) (JJ ...  \n",
       "9843  (ROOT (S (NP (NP (NNS Orders)) (PP (IN from) (...  \n",
       "9844  (ROOT (S (NP (NNS NEADS)) (VP (VBD learned) (P...  \n",
       "9845  (ROOT (S (S (NP (PRP I)) (VP (VBD asked))) (, ...  \n",
       "9846  (ROOT (S (NP (PRP He)) (VP (VBD was) (NP (NP (...  \n",
       "\n",
       "[9847 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_nli_test_mismatched\n",
    "#multi_nli_test_mismatched[multi_nli_test_mismatched.gold_label=='-']#意見が割れてる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f695f765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:20:55.701722Z",
     "iopub.status.busy": "2022-03-06T04:20:55.701042Z",
     "iopub.status.idle": "2022-03-06T04:20:55.885200Z",
     "shell.execute_reply": "2022-03-06T04:20:55.884696Z",
     "shell.execute_reply.started": "2021-10-11T11:54:04.663613Z"
    },
    "papermill": {
     "duration": 0.211533,
     "end_time": "2022-03-06T04:20:55.885322",
     "exception": false,
     "start_time": "2022-03-06T04:20:55.673789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer=transformers.BertTokenizer.from_pretrained(\"../input/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19c881ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:20:55.959483Z",
     "iopub.status.busy": "2022-03-06T04:20:55.944737Z",
     "iopub.status.idle": "2022-03-06T04:21:07.493771Z",
     "shell.execute_reply": "2022-03-06T04:21:07.494232Z",
     "shell.execute_reply.started": "2021-10-11T11:54:04.842356Z"
    },
    "papermill": {
     "duration": 11.584748,
     "end_time": "2022-03-06T04:21:07.494398",
     "exception": false,
     "start_time": "2022-03-06T04:20:55.909650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_nli_test_mismatched['sentence1_len']=multi_nli_test_mismatched.sentence1.apply(tokenizer.encode).apply(len)\n",
    "multi_nli_test_mismatched['sentence2_len']=multi_nli_test_mismatched.sentence2.apply(tokenizer.encode).apply(len)\n",
    "max_len=max(multi_nli_test_mismatched['sentence1_len']+multi_nli_test_mismatched['sentence2_len'])+3\n",
    "max_len#=448 #他のデータにもっと長いのあるかも"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7194632",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:07.548696Z",
     "iopub.status.busy": "2022-03-06T04:21:07.547963Z",
     "iopub.status.idle": "2022-03-06T04:21:07.550558Z",
     "shell.execute_reply": "2022-03-06T04:21:07.550160Z",
     "shell.execute_reply.started": "2021-10-11T11:54:04.978398Z"
    },
    "papermill": {
     "duration": 0.030999,
     "end_time": "2022-03-06T04:21:07.550677",
     "exception": false,
     "start_time": "2022-03-06T04:21:07.519678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_len=448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6980f42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:07.603786Z",
     "iopub.status.busy": "2022-03-06T04:21:07.603182Z",
     "iopub.status.idle": "2022-03-06T04:21:07.605833Z",
     "shell.execute_reply": "2022-03-06T04:21:07.605381Z",
     "shell.execute_reply.started": "2021-10-11T11:54:04.984525Z"
    },
    "papermill": {
     "duration": 0.030687,
     "end_time": "2022-03-06T04:21:07.605967",
     "exception": false,
     "start_time": "2022-03-06T04:21:07.575280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# multi_nli_dev_matched_val, multi_nli_dev_matched_test = sklearn.model_selection.train_test_split(\n",
    "#     multi_nli_dev_matched,\n",
    "#     test_size=0.8,\n",
    "#     random_state=CFG.seed, \n",
    "#     stratify=multi_nli_dev_matched[\"gold_label\"],\n",
    "# )\n",
    "\n",
    "# multi_nli_dev_mismatched_val, multi_nli_dev_mismatched_test = sklearn.model_selection.train_test_split(\n",
    "#     multi_nli_dev_mismatched,\n",
    "#     test_size=0.8,\n",
    "#     random_state=CFG.seed, \n",
    "#     stratify=multi_nli_dev_mismatched[\"gold_label\"],\n",
    "# )\n",
    "\n",
    "# multi_nli_train=multi_nli_train.reset_index(drop=True)\n",
    "\n",
    "# multi_nli_dev_matched_val=multi_nli_dev_matched_val.reset_index(drop=True)\n",
    "# multi_nli_dev_matched_test=multi_nli_dev_matched_test.reset_index(drop=True)\n",
    "\n",
    "# multi_nli_dev_mismatched_val=multi_nli_dev_mismatched_val.reset_index(drop=True)\n",
    "# multi_nli_dev_mismatched_test=multi_nli_dev_mismatched_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21edc875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:07.661712Z",
     "iopub.status.busy": "2022-03-06T04:21:07.660860Z",
     "iopub.status.idle": "2022-03-06T04:21:07.681821Z",
     "shell.execute_reply": "2022-03-06T04:21:07.682423Z",
     "shell.execute_reply.started": "2021-10-11T11:54:04.994597Z"
    },
    "papermill": {
     "duration": 0.051826,
     "end_time": "2022-03-06T04:21:07.682562",
     "exception": false,
     "start_time": "2022-03-06T04:21:07.630736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator_labels</th>\n",
       "      <th>genre</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>pairID</th>\n",
       "      <th>promptID</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence1_binary_parse</th>\n",
       "      <th>sentence1_parse</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence2_binary_parse</th>\n",
       "      <th>sentence2_parse</th>\n",
       "      <th>sentence1_len</th>\n",
       "      <th>sentence2_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>oup</td>\n",
       "      <td>hidden</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Even here, the channel perspective tells a som...</td>\n",
       "      <td>( ( Even here ) ( , ( ( the ( channel perspect...</td>\n",
       "      <td>(ROOT (S (ADVP (RB Even) (RB here)) (, ,) (NP ...</td>\n",
       "      <td>The story told by the channel is slightly diff...</td>\n",
       "      <td>( ( ( The story ) ( told ( by ( the channel ) ...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT The) (NN story)) (VP (VBN...</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>verbatim</td>\n",
       "      <td>hidden</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>My theory is that the  r got put in there simp...</td>\n",
       "      <td>( ( My theory ) ( ( is ( that ( ( the r ) ( ( ...</td>\n",
       "      <td>(ROOT (S (NP (PRP$ My) (NN theory)) (VP (VBZ i...</td>\n",
       "      <td>I think the r is there just because people are...</td>\n",
       "      <td>( I ( ( think ( ( the r ) ( ( is there ) ( jus...</td>\n",
       "      <td>(ROOT (S (NP (PRP I)) (VP (VBP think) (SBAR (S...</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>verbatim</td>\n",
       "      <td>hidden</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>To go on using in its former sense a word whos...</td>\n",
       "      <td>( ( To ( go ( on ( ( using ( in ( its ( former...</td>\n",
       "      <td>(ROOT (S (S (VP (TO To) (VP (VB go) (PP (IN on...</td>\n",
       "      <td>To go on using it in its former sense could be...</td>\n",
       "      <td>( ( To ( go ( on ( ( using it ) ( in ( its ( f...</td>\n",
       "      <td>(ROOT (NP (S (S (VP (TO To) (VP (VB go) (PP (I...</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>nineeleven</td>\n",
       "      <td>hidden</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>He alerted his supervisor, who assigned anothe...</td>\n",
       "      <td>( He ( ( alerted ( ( ( his supervisor ) , ) ( ...</td>\n",
       "      <td>(ROOT (S (NP (PRP He)) (VP (VBD alerted) (NP (...</td>\n",
       "      <td>The supervisor had another controller work wit...</td>\n",
       "      <td>( ( The supervisor ) ( ( had ( ( another ( con...</td>\n",
       "      <td>(ROOT (S (NP (DT The) (NN supervisor)) (VP (VB...</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>letters</td>\n",
       "      <td>hidden</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>I have also enclosed a brief report on those a...</td>\n",
       "      <td>( I ( ( ( have also ) ( ( enclosed ( a ( brief...</td>\n",
       "      <td>(ROOT (S (NP (PRP I)) (VP (VBP have) (ADVP (RB...</td>\n",
       "      <td>Your annual contribution will have little impact.</td>\n",
       "      <td>( ( Your ( annual contribution ) ) ( ( will ( ...</td>\n",
       "      <td>(ROOT (S (NP (PRP$ Your) (JJ annual) (NN contr...</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9842</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>facetoface</td>\n",
       "      <td>hidden</td>\n",
       "      <td>9842</td>\n",
       "      <td>9842</td>\n",
       "      <td>Grandmom smoked Saratoga 120 cigarettes which ...</td>\n",
       "      <td>( Grandmom ( ( smoked ( ( Saratoga ( 120 cigar...</td>\n",
       "      <td>(ROOT (S (NP (NNP Grandmom)) (VP (VBD smoked) ...</td>\n",
       "      <td>Those really long Saratoga 120 cigarettes are ...</td>\n",
       "      <td>( ( Those ( ( really long ) ( Saratoga ( 120 c...</td>\n",
       "      <td>(ROOT (S (NP (DT Those) (ADJP (RB really) (JJ ...</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9843</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>oup</td>\n",
       "      <td>hidden</td>\n",
       "      <td>9843</td>\n",
       "      <td>9843</td>\n",
       "      <td>But if order lead times are long, the buyer mu...</td>\n",
       "      <td>( But ( ( ( if order ) ( ( lead times ) ( are ...</td>\n",
       "      <td>(ROOT (S (CC But) (SBAR (IN if) (NN order) (S ...</td>\n",
       "      <td>Orders from China often take longer than expec...</td>\n",
       "      <td>( ( Orders ( from China ) ) ( often ( ( take (...</td>\n",
       "      <td>(ROOT (S (NP (NP (NNS Orders)) (PP (IN from) (...</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9844</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>nineeleven</td>\n",
       "      <td>hidden</td>\n",
       "      <td>9844</td>\n",
       "      <td>9844</td>\n",
       "      <td>After NEADS learned of the hijacking at 10:07,...</td>\n",
       "      <td>( ( After ( NEADS ( learned ( of ( ( the hijac...</td>\n",
       "      <td>(ROOT (S (PP (IN After) (NP (NP (NNS NEADS)) (...</td>\n",
       "      <td>NEADS learned of the hijacking at 10:07, befor...</td>\n",
       "      <td>( NEADS ( ( ( ( ( learned ( of ( the hijacking...</td>\n",
       "      <td>(ROOT (S (NP (NNS NEADS)) (VP (VBD learned) (P...</td>\n",
       "      <td>71</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>facetoface</td>\n",
       "      <td>hidden</td>\n",
       "      <td>9845</td>\n",
       "      <td>9845</td>\n",
       "      <td>I said, And do you think you can help me?</td>\n",
       "      <td>( ( ( ( I said ) , ) And ) ( ( ( do you ) ( th...</td>\n",
       "      <td>(ROOT (S (S (NP (PRP I)) (VP (VBD said))) (, ,...</td>\n",
       "      <td>I asked, so do you think you can help me with ...</td>\n",
       "      <td>( ( ( ( I asked ) , ) so ) ( ( ( do you ) ( th...</td>\n",
       "      <td>(ROOT (S (S (NP (PRP I)) (VP (VBD asked))) (, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9846</th>\n",
       "      <td>[hidden, hidden, hidden, hidden, hidden]</td>\n",
       "      <td>nineeleven</td>\n",
       "      <td>hidden</td>\n",
       "      <td>9846</td>\n",
       "      <td>9846</td>\n",
       "      <td>Still, he was just one among many diverse terr...</td>\n",
       "      <td>( Still ( , ( he ( ( was ( ( just one ) ( amon...</td>\n",
       "      <td>(ROOT (S (ADVP (RB Still)) (, ,) (NP (PRP he))...</td>\n",
       "      <td>He was just one of many lead terrorists.</td>\n",
       "      <td>( He ( ( was ( ( just one ) ( of ( many ( lead...</td>\n",
       "      <td>(ROOT (S (NP (PRP He)) (VP (VBD was) (NP (NP (...</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9847 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              annotator_labels       genre gold_label  pairID  \\\n",
       "0     [hidden, hidden, hidden, hidden, hidden]         oup     hidden       0   \n",
       "1     [hidden, hidden, hidden, hidden, hidden]    verbatim     hidden       1   \n",
       "2     [hidden, hidden, hidden, hidden, hidden]    verbatim     hidden       2   \n",
       "3     [hidden, hidden, hidden, hidden, hidden]  nineeleven     hidden       3   \n",
       "4     [hidden, hidden, hidden, hidden, hidden]     letters     hidden       4   \n",
       "...                                        ...         ...        ...     ...   \n",
       "9842  [hidden, hidden, hidden, hidden, hidden]  facetoface     hidden    9842   \n",
       "9843  [hidden, hidden, hidden, hidden, hidden]         oup     hidden    9843   \n",
       "9844  [hidden, hidden, hidden, hidden, hidden]  nineeleven     hidden    9844   \n",
       "9845  [hidden, hidden, hidden, hidden, hidden]  facetoface     hidden    9845   \n",
       "9846  [hidden, hidden, hidden, hidden, hidden]  nineeleven     hidden    9846   \n",
       "\n",
       "      promptID                                          sentence1  \\\n",
       "0            0  Even here, the channel perspective tells a som...   \n",
       "1            1  My theory is that the  r got put in there simp...   \n",
       "2            2  To go on using in its former sense a word whos...   \n",
       "3            3  He alerted his supervisor, who assigned anothe...   \n",
       "4            4  I have also enclosed a brief report on those a...   \n",
       "...        ...                                                ...   \n",
       "9842      9842  Grandmom smoked Saratoga 120 cigarettes which ...   \n",
       "9843      9843  But if order lead times are long, the buyer mu...   \n",
       "9844      9844  After NEADS learned of the hijacking at 10:07,...   \n",
       "9845      9845          I said, And do you think you can help me?   \n",
       "9846      9846  Still, he was just one among many diverse terr...   \n",
       "\n",
       "                                 sentence1_binary_parse  \\\n",
       "0     ( ( Even here ) ( , ( ( the ( channel perspect...   \n",
       "1     ( ( My theory ) ( ( is ( that ( ( the r ) ( ( ...   \n",
       "2     ( ( To ( go ( on ( ( using ( in ( its ( former...   \n",
       "3     ( He ( ( alerted ( ( ( his supervisor ) , ) ( ...   \n",
       "4     ( I ( ( ( have also ) ( ( enclosed ( a ( brief...   \n",
       "...                                                 ...   \n",
       "9842  ( Grandmom ( ( smoked ( ( Saratoga ( 120 cigar...   \n",
       "9843  ( But ( ( ( if order ) ( ( lead times ) ( are ...   \n",
       "9844  ( ( After ( NEADS ( learned ( of ( ( the hijac...   \n",
       "9845  ( ( ( ( I said ) , ) And ) ( ( ( do you ) ( th...   \n",
       "9846  ( Still ( , ( he ( ( was ( ( just one ) ( amon...   \n",
       "\n",
       "                                        sentence1_parse  \\\n",
       "0     (ROOT (S (ADVP (RB Even) (RB here)) (, ,) (NP ...   \n",
       "1     (ROOT (S (NP (PRP$ My) (NN theory)) (VP (VBZ i...   \n",
       "2     (ROOT (S (S (VP (TO To) (VP (VB go) (PP (IN on...   \n",
       "3     (ROOT (S (NP (PRP He)) (VP (VBD alerted) (NP (...   \n",
       "4     (ROOT (S (NP (PRP I)) (VP (VBP have) (ADVP (RB...   \n",
       "...                                                 ...   \n",
       "9842  (ROOT (S (NP (NNP Grandmom)) (VP (VBD smoked) ...   \n",
       "9843  (ROOT (S (CC But) (SBAR (IN if) (NN order) (S ...   \n",
       "9844  (ROOT (S (PP (IN After) (NP (NP (NNS NEADS)) (...   \n",
       "9845  (ROOT (S (S (NP (PRP I)) (VP (VBD said))) (, ,...   \n",
       "9846  (ROOT (S (ADVP (RB Still)) (, ,) (NP (PRP he))...   \n",
       "\n",
       "                                              sentence2  \\\n",
       "0     The story told by the channel is slightly diff...   \n",
       "1     I think the r is there just because people are...   \n",
       "2     To go on using it in its former sense could be...   \n",
       "3     The supervisor had another controller work wit...   \n",
       "4     Your annual contribution will have little impact.   \n",
       "...                                                 ...   \n",
       "9842  Those really long Saratoga 120 cigarettes are ...   \n",
       "9843  Orders from China often take longer than expec...   \n",
       "9844  NEADS learned of the hijacking at 10:07, befor...   \n",
       "9845  I asked, so do you think you can help me with ...   \n",
       "9846          He was just one of many lead terrorists.    \n",
       "\n",
       "                                 sentence2_binary_parse  \\\n",
       "0     ( ( ( The story ) ( told ( by ( the channel ) ...   \n",
       "1     ( I ( ( think ( ( the r ) ( ( is there ) ( jus...   \n",
       "2     ( ( To ( go ( on ( ( using it ) ( in ( its ( f...   \n",
       "3     ( ( The supervisor ) ( ( had ( ( another ( con...   \n",
       "4     ( ( Your ( annual contribution ) ) ( ( will ( ...   \n",
       "...                                                 ...   \n",
       "9842  ( ( Those ( ( really long ) ( Saratoga ( 120 c...   \n",
       "9843  ( ( Orders ( from China ) ) ( often ( ( take (...   \n",
       "9844  ( NEADS ( ( ( ( ( learned ( of ( the hijacking...   \n",
       "9845  ( ( ( ( I asked ) , ) so ) ( ( ( do you ) ( th...   \n",
       "9846  ( He ( ( was ( ( just one ) ( of ( many ( lead...   \n",
       "\n",
       "                                        sentence2_parse  sentence1_len  \\\n",
       "0     (ROOT (S (NP (NP (DT The) (NN story)) (VP (VBN...             14   \n",
       "1     (ROOT (S (NP (PRP I)) (VP (VBP think) (SBAR (S...             35   \n",
       "2     (ROOT (NP (S (S (VP (TO To) (VP (VB go) (PP (I...             21   \n",
       "3     (ROOT (S (NP (DT The) (NN supervisor)) (VP (VB...             15   \n",
       "4     (ROOT (S (NP (PRP$ Your) (JJ annual) (NN contr...             21   \n",
       "...                                                 ...            ...   \n",
       "9842  (ROOT (S (NP (DT Those) (ADJP (RB really) (JJ ...             19   \n",
       "9843  (ROOT (S (NP (NP (NNS Orders)) (PP (IN from) (...             31   \n",
       "9844  (ROOT (S (NP (NNS NEADS)) (VP (VBD learned) (P...             71   \n",
       "9845  (ROOT (S (S (NP (PRP I)) (VP (VBD asked))) (, ...             14   \n",
       "9846  (ROOT (S (NP (PRP He)) (VP (VBD was) (NP (NP (...             14   \n",
       "\n",
       "      sentence2_len  \n",
       "0                12  \n",
       "1                16  \n",
       "2                16  \n",
       "3                11  \n",
       "4                10  \n",
       "...             ...  \n",
       "9842             13  \n",
       "9843             11  \n",
       "9844             19  \n",
       "9845             17  \n",
       "9846             11  \n",
       "\n",
       "[9847 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_nli_test_mismatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75b6da5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:07.739396Z",
     "iopub.status.busy": "2022-03-06T04:21:07.738594Z",
     "iopub.status.idle": "2022-03-06T04:21:07.740535Z",
     "shell.execute_reply": "2022-03-06T04:21:07.740933Z",
     "shell.execute_reply.started": "2021-10-11T11:54:05.025682Z"
    },
    "papermill": {
     "duration": 0.031646,
     "end_time": "2022-03-06T04:21:07.741063",
     "exception": false,
     "start_time": "2022-03-06T04:21:07.709417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data={\n",
    "    'test':{\n",
    "        'mismatched':multi_nli_test_mismatched,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a85f224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:07.794788Z",
     "iopub.status.busy": "2022-03-06T04:21:07.794036Z",
     "iopub.status.idle": "2022-03-06T04:21:07.801731Z",
     "shell.execute_reply": "2022-03-06T04:21:07.801247Z",
     "shell.execute_reply.started": "2021-10-11T11:54:05.037511Z"
    },
    "papermill": {
     "duration": 0.035319,
     "end_time": "2022-03-06T04:21:07.801887",
     "exception": false,
     "start_time": "2022-03-06T04:21:07.766568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,sentences1,sentences2,targets=None,phase='train'):\n",
    "        self.sentences1=sentences1\n",
    "        self.sentences2=sentences2\n",
    "        self.targets=targets\n",
    "        self.phase=phase #train/val/test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences1)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        enc=tokenizer(\n",
    "            self.sentences1[idx],\n",
    "            self.sentences2[idx],\n",
    "            padding='max_length',\n",
    "            max_length=max_len,\n",
    "        )\n",
    "        return {\n",
    "            'input_ids':torch.tensor(enc['input_ids'],dtype=torch.long),\n",
    "            'attention_mask':torch.tensor(enc['attention_mask'],dtype=torch.float),\n",
    "            'token_type_ids':torch.tensor(enc['token_type_ids'],dtype=torch.long),\n",
    "            #'targets':torch.tensor(self.targets[idx],dtype=torch.float)\n",
    "        },torch.tensor(-1)\n",
    "    #torch.tensor(['entailment','neutral','contradiction'].index(self.targets[idx]))\n",
    "    #torch.tensor(list(map(lambda label: int(label==self.targets[idx]), ['entailment','neutral','contradiction'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68024b24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:07.857729Z",
     "iopub.status.busy": "2022-03-06T04:21:07.856986Z",
     "iopub.status.idle": "2022-03-06T04:21:07.858905Z",
     "shell.execute_reply": "2022-03-06T04:21:07.859299Z",
     "shell.execute_reply.started": "2021-10-11T11:54:05.047451Z"
    },
    "papermill": {
     "duration": 0.032105,
     "end_time": "2022-03-06T04:21:07.859410",
     "exception": false,
     "start_time": "2022-03-06T04:21:07.827305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_dataset():\n",
    "    global dataset\n",
    "    dataset={\n",
    "        'test'  :{\n",
    "            'mismatched':Dataset(\n",
    "                data['test']['mismatched'].sentence1,\n",
    "                data['test']['mismatched'].sentence2,\n",
    "                data['test']['mismatched'].gold_label,\n",
    "                'test'\n",
    "            ),\n",
    "        },\n",
    "    }\n",
    "\n",
    "set_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31f28038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:07.918525Z",
     "iopub.status.busy": "2022-03-06T04:21:07.917943Z",
     "iopub.status.idle": "2022-03-06T04:21:07.983147Z",
     "shell.execute_reply": "2022-03-06T04:21:07.983526Z",
     "shell.execute_reply.started": "2021-10-11T11:54:05.059758Z"
    },
    "papermill": {
     "duration": 0.098806,
     "end_time": "2022-03-06T04:21:07.983652",
     "exception": false,
     "start_time": "2022-03-06T04:21:07.884846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([  101,  2000,  2175,  2006,  2478,  1999,  2049,  2280,  3168,  1037,\n",
       "           2773,  3005,  3574,  2038,  2904,  2003,  4675, 21572, 26638,  1012,\n",
       "            102,  2000,  2175,  2006,  2478,  2009,  1999,  2049,  2280,  3168,\n",
       "           2071,  2022,  2641,  2062,  6742,   102,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0]),\n",
       "  'attention_mask': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])},\n",
       " tensor(-1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']['mismatched'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ceeca91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:08.041276Z",
     "iopub.status.busy": "2022-03-06T04:21:08.040539Z",
     "iopub.status.idle": "2022-03-06T04:21:08.043199Z",
     "shell.execute_reply": "2022-03-06T04:21:08.042699Z",
     "shell.execute_reply.started": "2021-10-11T11:54:05.133914Z"
    },
    "papermill": {
     "duration": 0.033704,
     "end_time": "2022-03-06T04:21:08.043306",
     "exception": false,
     "start_time": "2022-03-06T04:21:08.009602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_dataloader():\n",
    "    global dataloader\n",
    "    dataloader={\n",
    "        'test':{\n",
    "            'mismatched':torch.utils.data.DataLoader(\n",
    "                dataset['test']['mismatched'],\n",
    "                batch_size=CFG.batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=os.cpu_count(),\n",
    "                pin_memory=True\n",
    "            ),\n",
    "        },\n",
    "    }\n",
    "set_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6159755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:08.097920Z",
     "iopub.status.busy": "2022-03-06T04:21:08.097418Z",
     "iopub.status.idle": "2022-03-06T04:21:24.286842Z",
     "shell.execute_reply": "2022-03-06T04:21:24.287296Z",
     "shell.execute_reply.started": "2021-10-11T11:58:26.674539Z"
    },
    "papermill": {
     "duration": 16.218537,
     "end_time": "2022-03-06T04:21:24.287475",
     "exception": false,
     "start_time": "2022-03-06T04:21:08.068938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bestmodel=torch.load(\"../input/argument-mining-graduation-thesis/bert_mnli_0.8428280773143438.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c6fb588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:24.353082Z",
     "iopub.status.busy": "2022-03-06T04:21:24.351871Z",
     "iopub.status.idle": "2022-03-06T04:21:24.355169Z",
     "shell.execute_reply": "2022-03-06T04:21:24.355570Z",
     "shell.execute_reply.started": "2021-10-11T12:03:56.756223Z"
    },
    "papermill": {
     "duration": 0.038287,
     "end_time": "2022-03-06T04:21:24.355708",
     "exception": false,
     "start_time": "2022-03-06T04:21:24.317421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8428280773143438"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodel['bestscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "992836e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:24.418556Z",
     "iopub.status.busy": "2022-03-06T04:21:24.417983Z",
     "iopub.status.idle": "2022-03-06T04:21:31.559107Z",
     "shell.execute_reply": "2022-03-06T04:21:31.559536Z",
     "shell.execute_reply.started": "2021-10-11T12:19:42.373926Z"
    },
    "papermill": {
     "duration": 7.174608,
     "end_time": "2022-03-06T04:21:31.559684",
     "exception": false,
     "start_time": "2022-03-06T04:21:24.385076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ../input/bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##create_token_type_ids_from_sequences\n",
    "model = transformers.BertForSequenceClassification.from_pretrained(\"../input/bert-base-uncased\",num_labels=3)\n",
    "model.to(CFG.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19cf3b3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:31.618629Z",
     "iopub.status.busy": "2022-03-06T04:21:31.618126Z",
     "iopub.status.idle": "2022-03-06T04:21:31.635216Z",
     "shell.execute_reply": "2022-03-06T04:21:31.634749Z"
    },
    "papermill": {
     "duration": 0.048283,
     "end_time": "2022-03-06T04:21:31.635332",
     "exception": false,
     "start_time": "2022-03-06T04:21:31.587049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(bestmodel['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00026921",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:31.693773Z",
     "iopub.status.busy": "2022-03-06T04:21:31.693060Z",
     "iopub.status.idle": "2022-03-06T04:21:31.695145Z",
     "shell.execute_reply": "2022-03-06T04:21:31.695510Z",
     "shell.execute_reply.started": "2021-10-11T11:54:35.231136Z"
    },
    "papermill": {
     "duration": 0.03275,
     "end_time": "2022-03-06T04:21:31.695627",
     "exception": false,
     "start_time": "2022-03-06T04:21:31.662877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = torch.randn(4, 3)\n",
    "# a\n",
    "# b=torch.tensor([1,2,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d8859aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:31.754323Z",
     "iopub.status.busy": "2022-03-06T04:21:31.753562Z",
     "iopub.status.idle": "2022-03-06T04:21:31.755880Z",
     "shell.execute_reply": "2022-03-06T04:21:31.755489Z",
     "shell.execute_reply.started": "2021-10-11T11:54:35.233463Z"
    },
    "papermill": {
     "duration": 0.033031,
     "end_time": "2022-03-06T04:21:31.756012",
     "exception": false,
     "start_time": "2022-03-06T04:21:31.722981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.argmax(a,dim=1)==b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4238f9aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:31.815229Z",
     "iopub.status.busy": "2022-03-06T04:21:31.814477Z",
     "iopub.status.idle": "2022-03-06T04:21:31.816861Z",
     "shell.execute_reply": "2022-03-06T04:21:31.816465Z",
     "shell.execute_reply.started": "2021-10-11T12:20:47.74332Z"
    },
    "papermill": {
     "duration": 0.033538,
     "end_time": "2022-03-06T04:21:31.816992",
     "exception": false,
     "start_time": "2022-03-06T04:21:31.783454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_fun(preds,y):\n",
    "    return (torch.argmax(preds,dim=1)==y).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c80dd76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:31.898002Z",
     "iopub.status.busy": "2022-03-06T04:21:31.884992Z",
     "iopub.status.idle": "2022-03-06T04:21:31.901824Z",
     "shell.execute_reply": "2022-03-06T04:21:31.902364Z",
     "shell.execute_reply.started": "2021-10-11T12:20:49.105427Z"
    },
    "papermill": {
     "duration": 0.057982,
     "end_time": "2022-03-06T04:21:31.902496",
     "exception": false,
     "start_time": "2022-03-06T04:21:31.844514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-05.\n"
     ]
    }
   ],
   "source": [
    "class Trainer():\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.loss_fun=torch.nn.CrossEntropyLoss()\n",
    "        self.score_fun=score_fun\n",
    "\n",
    "        self.optimizer=torch.optim.AdamW(model.parameters(),lr=CFG.learning_rate,eps=1e-6)\n",
    "        self.scheduler=torch.optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda = lambda epoch: 0.95 ** epoch, verbose=True)\n",
    "        #scaler=scaler\n",
    "        #self.initialize()\n",
    "    \n",
    "    def train_val_test(self,model,dataloader,phase):\n",
    "    \n",
    "        preds=[]\n",
    "        losses=[]\n",
    "        scores=[]\n",
    "        \n",
    "        model.train() if phase=='train' else model.eval()# モデルのモード\n",
    "        \n",
    "        # データローダーからミニバッチを取り出すループ\n",
    "        \n",
    "        for features,targets in tqdm(dataloader):\n",
    "            \n",
    "            # optimizerを初期化\n",
    "            if phase=='train':self.optimizer.zero_grad()\n",
    "\n",
    "            # 順伝搬（forward）計算\n",
    "            with torch.set_grad_enabled(phase=='train'):\n",
    " \n",
    "                input_ids      =features['input_ids'].to(CFG.device,non_blocking=True)\n",
    "                attention_mask =features['attention_mask'].to(CFG.device,non_blocking=True)\n",
    "                token_type_ids=features['token_type_ids'].to(CFG.device,non_blocking=True)\n",
    "                targets        =targets.to(CFG.device,non_blocking=True)\n",
    "                \n",
    "                #with torch.cuda.amp.autocast():\n",
    "\n",
    "                \n",
    "                outputs = model(input_ids,attention_mask,token_type_ids)#,labels=targets)\n",
    "                \n",
    "#                 print(outputs)\n",
    "#                 print(targets)\n",
    "\n",
    "                    \n",
    "                #if phase!='test':\n",
    "        \n",
    "#                 #loss = self.loss_fun(outputs, targets)  # 損失を計算\n",
    "#                 loss=outputs.loss\n",
    "#                 score = self.score_fun(outputs.logits, targets)  # 損失を計算\n",
    "#                 #print(score)\n",
    "#                 losses.append(loss.item())\n",
    "#                 scores.extend(score)\n",
    "\n",
    "                # 訓練時はバックプロパゲーション\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    #loss_val.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    #scalerの場合\n",
    "                    #scaler.scale(loss_val).backward() # ロスのバックワード\n",
    "                    #scaler.step(optimizer) # オプティマイザーの更新\n",
    "                    #scaler.update() # スケーラーの更新\n",
    "\n",
    "                    #scheduler.step() # 学習率の更新 ここに入れるべき？　まだ使わない\n",
    "                        \n",
    "            #preds.extend(outputs.logits.detach().cpu().numpy())\n",
    "            \n",
    "            #print(outputs)\n",
    "            \n",
    "            #print(((list(map(lambda x: ['entailment','neutral','contradiction'][x], torch.argmax(outputs.logits,dim=1).detach().cpu().numpy())))))\n",
    "            \n",
    "            preds.extend(((list(map(lambda x: ['entailment','neutral','contradiction'][x], torch.argmax(outputs.logits,dim=1).detach().cpu().numpy())))))\n",
    "            \n",
    "            \n",
    "            del features,targets,outputs\n",
    "            #if phase!='test':del loss,score\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "        return preds,losses,scores\n",
    "    \n",
    "    def cross_validation(self,model,dataloader):\n",
    "        \n",
    "        for fold in range(CFG.kFold):\n",
    "            print('fold',fold)\n",
    "            \n",
    "            losses=[]\n",
    "            scores=[]\n",
    "            \n",
    "            #self.initialize(CFG.seed,fold)\n",
    "            #dataset,dataloader,model,optimizer,scheduler,scaler=initialize(CFG.seed,fold)\n",
    "            \n",
    "            bestscore=0\n",
    "            \n",
    "            tqdm_bar=io.StringIO()\n",
    "            for epoch in tqdm(range(CFG.epochs),file=tqdm_bar,desc='BERT Multi-NLI'):\n",
    "                print(\"epoch=\",epoch)\n",
    "\n",
    "                preds,_,score=self.train_val_test(model,dataloader['train'],'train')\n",
    "                print(color(\"train score\",bg='CYAN')+' :',color(np.mean(score),'CYAN'))\n",
    "                \n",
    "                #plt.scatter(dataset['train'].targets,preds,color='blue',s=5)\n",
    "                \n",
    "                #matched\n",
    "                _,loss,score=self.train_val_test(model,dataloader['val']['matched'],'val')\n",
    "                print(np.mean(loss))\n",
    "                print(color(\"matched score\",bg='BLUE')+' :',color(np.mean(score),'BLUE'))\n",
    "                \n",
    "                #mismatched\n",
    "                _,loss,score=self.train_val_test(model,dataloader['val']['mismatched'],'val')\n",
    "                print(np.mean(loss))\n",
    "                print(color(\"mismatched score\",bg='RED')+' :',color(np.mean(score),'RED'))\n",
    "                \n",
    "                scores.append(np.mean(score))\n",
    "                losses.append(np.mean(loss))\n",
    "                \n",
    "                self.optimizer.step()\n",
    "                \n",
    "                #print(scores[-1])\n",
    "\n",
    "                if bestscore < scores[-1]:\n",
    "                    bestscore = scores[-1]\n",
    "                    print(color(\"BEST SCORE\",bg='YELLOW')+' :',color(bestscore,'YELLOW'))\n",
    "\n",
    "                    bestmodel={\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'optimizer_dict': self.optimizer.state_dict(),\n",
    "                        'bestscore':bestscore,\n",
    "                        'seed':CFG.seed\n",
    "                    }\n",
    "\n",
    "                #print(preds)\n",
    "\n",
    "                slack.update(\n",
    "                    timestamp,\n",
    "                    slack.textblock(\n",
    "                        tqdm_bar.getvalue().split('\\r')[-1]+\n",
    "                        f\"loss={losses[-1]:.2f} score={scores[-1]:.2f} \"\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "            pd.Series(losses).plot()\n",
    "            plt.show()\n",
    "            pd.Series(scores).plot()\n",
    "            plt.show()\n",
    "\n",
    "            torch.save(bestmodel,\"bert_mnli_\"+str(bestscore)+\".pth\")\n",
    "\n",
    "#             plt.plot(losses['train'],color='blue')\n",
    "#             plt.plot(losses['valid'],color='red')\n",
    "#             plt.show()\n",
    "    \n",
    "            \n",
    "trainer=Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13f683ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:31.961999Z",
     "iopub.status.busy": "2022-03-06T04:21:31.961463Z",
     "iopub.status.idle": "2022-03-06T04:21:31.964839Z",
     "shell.execute_reply": "2022-03-06T04:21:31.964420Z",
     "shell.execute_reply.started": "2021-10-11T11:54:35.238987Z"
    },
    "papermill": {
     "duration": 0.034509,
     "end_time": "2022-03-06T04:21:31.964973",
     "exception": false,
     "start_time": "2022-03-06T04:21:31.930464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer.cross_validation(model,dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a56428b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:32.024931Z",
     "iopub.status.busy": "2022-03-06T04:21:32.024420Z",
     "iopub.status.idle": "2022-03-06T04:21:32.027798Z",
     "shell.execute_reply": "2022-03-06T04:21:32.027368Z",
     "shell.execute_reply.started": "2021-10-11T11:54:35.240838Z"
    },
    "papermill": {
     "duration": 0.035173,
     "end_time": "2022-03-06T04:21:32.027919",
     "exception": false,
     "start_time": "2022-03-06T04:21:31.992746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preds,losses,scores=trainer.train_val_test(model,dataloader['test']['matched'],'test')\n",
    "# print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2ea0e1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:21:32.089125Z",
     "iopub.status.busy": "2022-03-06T04:21:32.088304Z",
     "iopub.status.idle": "2022-03-06T04:26:32.886780Z",
     "shell.execute_reply": "2022-03-06T04:26:32.886213Z",
     "shell.execute_reply.started": "2021-10-11T12:20:51.186006Z"
    },
    "papermill": {
     "duration": 300.83124,
     "end_time": "2022-03-06T04:26:32.887008",
     "exception": false,
     "start_time": "2022-03-06T04:21:32.055768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1231/1231 [05:00<00:00,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "preds,losses,scores=trainer.train_val_test(model,dataloader['test']['mismatched'],'test')\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1458e8ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:26:33.580289Z",
     "iopub.status.busy": "2022-03-06T04:26:33.579475Z",
     "iopub.status.idle": "2022-03-06T04:26:33.582078Z",
     "shell.execute_reply": "2022-03-06T04:26:33.581565Z",
     "shell.execute_reply.started": "2021-10-11T12:21:02.488774Z"
    },
    "papermill": {
     "duration": 0.351847,
     "end_time": "2022-03-06T04:26:33.582219",
     "exception": false,
     "start_time": "2022-03-06T04:26:33.230372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f112bce7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:26:34.271282Z",
     "iopub.status.busy": "2022-03-06T04:26:34.270513Z",
     "iopub.status.idle": "2022-03-06T04:26:34.273050Z",
     "shell.execute_reply": "2022-03-06T04:26:34.272540Z",
     "shell.execute_reply.started": "2021-10-11T11:54:35.246606Z"
    },
    "papermill": {
     "duration": 0.348474,
     "end_time": "2022-03-06T04:26:34.273165",
     "exception": false,
     "start_time": "2022-03-06T04:26:33.924691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# slack.update(\n",
    "#     timestamp,\n",
    "#     slack.textblock(\n",
    "#         f\"train completed. loss={np.mean(losses):.2f} score={np.mean(scores):.2f} \"\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa59664f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:26:35.255108Z",
     "iopub.status.busy": "2022-03-06T04:26:35.254283Z",
     "iopub.status.idle": "2022-03-06T04:26:35.256843Z",
     "shell.execute_reply": "2022-03-06T04:26:35.256427Z",
     "shell.execute_reply.started": "2021-10-11T11:54:35.248483Z"
    },
    "papermill": {
     "duration": 0.486981,
     "end_time": "2022-03-06T04:26:35.256972",
     "exception": false,
     "start_time": "2022-03-06T04:26:34.769991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'bert_multi_nli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a64e828",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:26:35.956164Z",
     "iopub.status.busy": "2022-03-06T04:26:35.955486Z",
     "iopub.status.idle": "2022-03-06T04:26:35.958409Z",
     "shell.execute_reply": "2022-03-06T04:26:35.958798Z",
     "shell.execute_reply.started": "2021-10-11T12:21:11.725112Z"
    },
    "papermill": {
     "duration": 0.358452,
     "end_time": "2022-03-06T04:26:35.958986",
     "exception": false,
     "start_time": "2022-03-06T04:26:35.600534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        gold_label\n",
       "pairID            \n",
       "0       entailment\n",
       "1          neutral\n",
       "2          neutral\n",
       "3       entailment\n",
       "4          neutral"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.DataFrame(index=data['test']['mismatched'].pairID,columns=['gold_label'])\n",
    "\n",
    "#submission.index=\n",
    "submission.gold_label=preds\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c902733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-06T04:26:36.645900Z",
     "iopub.status.busy": "2022-03-06T04:26:36.645111Z",
     "iopub.status.idle": "2022-03-06T04:26:36.671829Z",
     "shell.execute_reply": "2022-03-06T04:26:36.671433Z",
     "shell.execute_reply.started": "2021-10-11T11:54:35.25211Z"
    },
    "papermill": {
     "duration": 0.3701,
     "end_time": "2022-03-06T04:26:36.671967",
     "exception": false,
     "start_time": "2022-03-06T04:26:36.301867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\",index='pairID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b019425",
   "metadata": {
    "papermill": {
     "duration": 0.339737,
     "end_time": "2022-03-06T04:26:37.355343",
     "exception": false,
     "start_time": "2022-03-06T04:26:37.015606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 357.815261,
   "end_time": "2022-03-06T04:26:40.699816",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-06T04:20:42.884555",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
