{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defaul libraries\n",
    "#https://docs.python.org/ja/\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "\n",
    "import math\n",
    "import random\n",
    "import pprint\n",
    "import time\n",
    "import datetime\n",
    "import typing\n",
    "import json\n",
    "import glob\n",
    "import requests\n",
    "import warnings\n",
    "import gc\n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "import numpy as np #https://numpy.org/\n",
    "import pandas as pd #https://pandas.pydata.org/\n",
    "import sklearn #https://scikit-learn.org/stable/\n",
    "\n",
    "import matplotlib.pyplot as plt #https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from tqdm import tqdm #https://tqdm.github.io/\n",
    "\n",
    "import torch #https://pytorch.org/\n",
    "import transformers #https://huggingface.co/transformers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG():\n",
    "    \n",
    "    data_path=\"path/to/datasets/\"\n",
    "    save_path=''\n",
    "    debug=False\n",
    "    seed=0\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    batch_size=128\n",
    "    epochs=20\n",
    "    learning_rate=1#0.001\n",
    "    kFold=1\n",
    "    amp=True\n",
    "\n",
    "    #高速化関連\n",
    "    #https://qiita.com/sugulu_Ogawa_ISID/items/62f5f7adee083d96a587\n",
    "\n",
    "    #GPU 遅くなるらしい↓\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    #イテレーションごとのnnの順伝搬および誤差関数の 計算手法がある程度一定であれば、torch.backends.cudnn.benchmark = Trueで GPU での計算が高速化\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    #tf.random.set_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "torch.cuda.set_device(CFG.device)\n",
    "set_seed(CFG.seed)\n",
    "print(CFG.device)\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color(string,fg='DEFAULT',bg='DEFAULT',fg_rgb=None,bg_rgb=None,style='END'):\n",
    "    colors=['BLACK','RED','GREEN','YELLOW','BLUE','PURPLE','CYAN','WHITE','8','DEFAULT']\n",
    "    styles=['END','BOLD','2','3','UNDERLINE','5','6','REVERSE','INVISIBLE','9']\n",
    "\n",
    "    fg=f'\\033[3{colors.index(fg)}m'\n",
    "    bg=f'\\033[4{colors.index(bg)}m'\n",
    "    style=f'\\033[0{styles.index(style)}m'\n",
    "\n",
    "    if fg_rgb:fg=f\"\\033[38;2;{fg_rgb[0]};{fg_rgb[1]};{fg_rgb[2]}m\"\n",
    "    if bg_rgb:bg=f\"\\033[48;2;{bg_rgb[0]};{bg_rgb[1]};{bg_rgb[2]}m\"\n",
    "\n",
    "    return style+fg+bg+str(string)+'\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\n",
    "    'train':pd.DataFrame(columns=['feature','target']),\n",
    "    'val':pd.DataFrame({'feature':val.feature,'target':val['target']}),\n",
    "    'test':pd.DataFrame(test),\n",
    "}\n",
    "\n",
    "#データの読み込み\n",
    "#data=pd.read_pickle('../dataset')\n",
    "\n",
    "#sample\n",
    "if CFG.debug:\n",
    "    data=data.sample(frac=0.01,random_state=CFG.seed)\n",
    "    data.reset_index(drop=True,inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'train':None,'val':None}\n",
    "from sklearn.model_selection import train_test_split\n",
    "data['train'], data['val'] = sklearn.model_selection.train_test_split(\n",
    "    data_,\n",
    "    test_size=0.2,\n",
    "    random_state=CFG.seed, \n",
    "    stratify=data_[\"target\"],\n",
    ")\n",
    "data['train']=data['train'].reset_index(drop=True)\n",
    "data['val']=data['val'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,features,targets=None,phase='train',transform=None):\n",
    "        self.features=features\n",
    "        self.targets=targets\n",
    "        self.phase=phase #train/val/test\n",
    "        self.transform=transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        if self.transform:datum=self.transform(self.features[idx])\n",
    "        \n",
    "        datum={\n",
    "            'train':{\n",
    "                'feature':self.features[idx],\n",
    "                'target':self.targets[idx],\n",
    "            },\n",
    "            'val':{\n",
    "                'feature':self.features[idx],\n",
    "                'target':self.targets[idx],\n",
    "            },\n",
    "            'test':{\n",
    "                'feature':self.features[idx],\n",
    "                'target':self.targets[idx],\n",
    "            }\n",
    "        }\n",
    "        return datum[phase].features,datum[phase].targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset={\n",
    "    'train':Dataset(data['train'].feature,data['train'].target),\n",
    "    'val'  :Dataset(data['val'].feature,  data['val'].target  ),\n",
    "    'test' :Dataset(data['test'].feature, data['test'].target ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collate_fn(batch):\n",
    "#     features,targets = zip(*batch)\n",
    "#     return features,torch.tensor(targets).float()\n",
    "\n",
    "dataloader={\n",
    "    'train':\n",
    "    torch.utils.data.DataLoader(\n",
    "        dataset['train'],\n",
    "        #collate_fn=sentences_collate_fn,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=os.cpu_count(),\n",
    "        pin_memory=True\n",
    "    ),\n",
    "    'val':\n",
    "    torch.utils.data.DataLoader(\n",
    "        dataset['val'],\n",
    "        #collate_fn=sentences_collate_fn,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=os.cpu_count(),\n",
    "        pin_memory=True\n",
    "    ),\n",
    "    'test':\n",
    "    torch.utils.data.DataLoader(\n",
    "        dataset['test'],\n",
    "        #collate_fn=sentences_collate_fn,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=os.cpu_count(),\n",
    "        pin_memory=True\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動作確認\n",
    "inputs, labels = next(iter(dataloader[\"train\"]))  # 1番目の要素を取り出す\n",
    "print(inputs.size())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.F.relu(self.conv1(x))\n",
    "        return torch.F.relu(self.conv2(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model()\n",
    "\n",
    "model.to(CFG.device)\n",
    "\n",
    "model.require_grad=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_fun=torch.nn.BCEWithLogitsLoss()\n",
    "        self.score_fun=lambda a,b:torch.eq(a>0.5,b>0.5)\n",
    "\n",
    "        self.optimizer=None\n",
    "        self.lr_scheduler=None\n",
    "        self.scaler=torch.cuda.amp.GradScaler(enabled=CFG.amp) \n",
    "\n",
    "    \n",
    "    def train_val_test(self,model,dataloader,phase,epoch=-1):\n",
    "\n",
    "        model.train() if phase=='train' else model.eval()   # モデルのモード\n",
    "        #model.to(CFG.device)\n",
    "\n",
    "        predictions=[]\n",
    "        losses=[]\n",
    "        scores=[]\n",
    "\n",
    "        # データローダーからミニバッチを取り出すループ\n",
    "\n",
    "        tqdm_bar=io.StringIO()\n",
    "        for features,targets in tqdm(dataloader,file=tqdm_bar,desc=f'model description\\n{epoch=} {phase=}'):\n",
    "            \n",
    "            # optimizerを初期化\n",
    "            if phase=='train':self.optimizer.zero_grad()\n",
    "\n",
    "            # 順伝搬（forward）計算\n",
    "            with torch.set_grad_enabled(phase=='train'):\n",
    " \n",
    "                features = features.to(CFG.device,non_blocking=True)\n",
    "                targets = targets.to(CFG.device,non_blocking=True)\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=CFG.amp):\n",
    "\n",
    "                    preds=model(features)#,targets)\n",
    "\n",
    "                    if phase!='test':\n",
    "                        loss = self.loss_fun(preds, targets)  # 損失を計算\n",
    "                        losses.append(loss.item())\n",
    " \n",
    "                        score = self.score_fun(preds, targets).cpu().numpy()  # 正誤判定\n",
    "                        scores.extend(score)\n",
    "\n",
    "                # 訓練時はバックプロパゲーション\n",
    "                if phase == 'train':\n",
    "                    if CFG.amp:\n",
    "                        #scalerの場合\n",
    "                        self.scaler.scale(loss).backward() # ロスのバックワード\n",
    "                        self.scaler.step(self.optimizer) # オプティマイザーの更新\n",
    "                        self.scaler.update() # スケーラーの更新\n",
    "                    else:\n",
    "                        loss.backward()\n",
    "                        self.optimizer.step()\n",
    "\n",
    "            predictions.extend(preds.detach().cpu().numpy())\n",
    "\n",
    "            del preds\n",
    "            if phase!='test':del loss,score\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            slack.update(\n",
    "                '1635484096.026100',\n",
    "                slack.textblock(\n",
    "                    tqdm_bar.getvalue().split('\\r')[-1]+\n",
    "                    f\"\\nscore={np.mean(scores):.3f}\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        return predictions,losses,scores\n",
    "\n",
    "    def cross_validation(self,model,dataloader):\n",
    "\n",
    "        start_time=datetime.datetime.utcnow() + datetime.timedelta(hours=9)\n",
    "\n",
    "        self.optimizer=transformers.AdamW(model.parameters(), CFG.learning_rate,betas=(0.9, 0.999), weight_decay=1e-2)\n",
    "        self.lr_scheduler=torch.optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda=lambda epoch:(1e-4)*(0.5**(epoch//5)),verbose=True)\n",
    "        \n",
    "        for fold in range(CFG.kFold):\n",
    "            print('fold',fold)\n",
    "            \n",
    "            losses={'train':[],'val':[]}\n",
    "            scores={'train':[],'val':[]}\n",
    "            \n",
    "            #self.initialize(CFG.seed,fold)\n",
    "            #dataset,dataloader,model,optimizer,scheduler,scaler=initialize(CFG.seed,fold)\n",
    "            \n",
    "            bestscore=0\n",
    "            \n",
    "            for epoch in tqdm(range(CFG.epochs)):\n",
    "                print(\"epoch=\",epoch)\n",
    "\n",
    "                # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n",
    "                # if (epoch == 0) and (phase == 'train'):train_continue\n",
    "\n",
    "                _,loss,score=self.train_val_test(model,dataloader['train'],'train',epoch=epoch)\n",
    "                print(color(\"train score\",bg='CYAN')+' :',color(np.mean(score),'CYAN'))\n",
    "                scores['train'].append(np.mean(score))\n",
    "                losses['train'].append(np.mean(loss))\n",
    "                \n",
    "                #plt.scatter(dataset['train'].targets,preds,color='blue',s=5)\n",
    "                \n",
    "                _,loss,score=self.train_val_test(model,dataloader['val'],'val',epoch=epoch)\n",
    "                print(np.mean(loss))\n",
    "                print(color(\"val score\",bg='RED')+' :',color(np.mean(score),'RED'))\n",
    "                \n",
    "                scores['val'].append(np.mean(score))\n",
    "                losses['val'].append(np.mean(loss))\n",
    "\n",
    "                #print(scores[-1])\n",
    "\n",
    "                if bestscore < scores['val'][-1]:\n",
    "                    bestscore = scores['val'][-1]\n",
    "                    print(color(\"BEST SCORE\",bg='YELLOW')+' :',color(bestscore,'YELLOW'))\n",
    "\n",
    "                    bestmodel={\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'optimizer_dict': self.optimizer.state_dict(),\n",
    "                        'bestscore':bestscore,\n",
    "                        'seed':CFG.seed\n",
    "                    }\n",
    "\n",
    "                #print(preds)\n",
    "\n",
    "                self.lr_scheduler.step() # 学習率の更新 \n",
    "                \n",
    "            plt.plot(range(CFG.epochs),losses['train'],color = \"blue\",label='train')\n",
    "            plt.plot(range(CFG.epochs),losses['val'],color = \"red\",label='val')\n",
    "            plt.legend()\n",
    "            plt.title('Loss')\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(range(CFG.epochs),scores['train'],color = \"blue\",label='train')\n",
    "            plt.plot(range(CFG.epochs),scores['val'],color = \"red\",label='val')\n",
    "            plt.plot(range(CFG.epochs),[0.644]*CFG.epochs,color = \"green\",linestyle = \"dotted\",label='Egawa model')\n",
    "            plt.legend()\n",
    "            plt.title('Score')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        exe_time=datetime.datetime.utcnow() + datetime.timedelta(hours=9)-start_time\n",
    "        print(exe_time)\n",
    "        slack.update(\n",
    "            '1635484096.026100',\n",
    "            slack.textblock(\n",
    "                f\"学習終了\\n実行時間：{exe_time}\\n{bestscore=:.3f}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        torch.save(bestmodel,\"egawa_model+BERT_NLI_v3:\"+str(bestscore)+\".pth\")\n",
    "            \n",
    "\n",
    "#             plt.plot(losses['train'],color='blue')\n",
    "#             plt.plot(losses['valid'],color='red')\n",
    "#             plt.show()\n",
    "\n",
    "trainer=Trainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.cross_validation(model,dataloader['CMV'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
